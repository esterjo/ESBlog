[{"authors":["admin"],"categories":null,"content":"Edger Sterjo is a mathematician working in the financial industry as a \u0026ldquo;quant\u0026rdquo; and data scientist. He is a pure mathematician at heart, but with a deep appreciation of mathematics that is applicable to real world problems. His current mathematical interests include dynamic programming, non-parametric Bayesian models, and (on weekends) mathematical physics.\n","date":1554595200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1554595200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/edger-sterjo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/edger-sterjo/","section":"authors","summary":"Edger Sterjo is a mathematician working in the financial industry as a \u0026ldquo;quant\u0026rdquo; and data scientist. He is a pure mathematician at heart, but with a deep appreciation of mathematics that is applicable to real world problems.","tags":null,"title":"Edger Sterjo","type":"authors"},{"authors":["吳恩達"],"categories":null,"content":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"d8f258c323db746988131e8c2d192f9a","permalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","section":"authors","summary":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"吳恩達","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":null,"title":"Example Talk","type":"talk"},{"authors":null,"categories":["R","C++"],"content":"\rIntroduction\rIn the first post in this series we discussed Expectation Maximization (EM) type algorithms. In the post prior to this one we discussed regularization and showed how it leads to a bias-variance trade off in OLS models. Here we implement fitting for \\(L^2\\)-regularized probit regression using EM. To make it more interesting we will code everything from scratch using the Eigen linear algebra library, via RcppEigen.\n\rProbit Regression as a censored OLS model\rIn our first post on EM algorithms we emphasized that EM is particularly useful for models that have censored data. Suppose we have the following censored model. Suppose \\(Y^*\\) is a real valued random variable and \\(\\vec{X}\\) is a random vector with values in \\(\\mathbb{R}^p\\). Suppose that we have the conditional relationship\n\\[\rY^* \\ \\ | \\ \\ \\vec{X} \\sim \\mathcal{N}(\\ \\langle \\vec{X} , \\beta\\rangle \\ ,\\ 1)\r\\]\nwhere \\(\\mathcal{N}(\\mu, \\sigma^2)\\) denotes the univariate normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\). Here (and everywhere else) the symbol \\(\\langle v,w\\rangle\\) represents the Euclidean inner product (aka, dot product) of two vectors \\(v\\) and \\(w\\).\nIn this case we may write \\(Y^* = \\langle \\vec{X} , \\beta\\rangle - \\epsilon\\), where \\(\\epsilon \\sim \\mathcal{N}(0,1)\\) is standard normal, which can be taken independent of \\(\\vec{X}\\) or this distribution can be simply assumed conditional on \\(\\vec{X}\\).\nInstead of observing \\(Y^*\\) in the data however, we observe the censored variable\r\\[\rY := \\begin{cases}\r1, \u0026amp; \\text{if} \\ \\ Y^* \u0026gt; 0 \\\\\r0, \u0026amp; \\text{otherwise}\r\\end{cases}\r\\]\rHence we have that \\(Y \\ |\\vec{X} \\sim \\text{Bernoulli}(p)\\) where\r\\[\rp = P(Y = 1 | \\vec{X}) = P(Y^* \u0026gt; 0 | \\vec{X}) = P\\bigg(Y^* - \\langle \\vec{X},\\beta\\rangle \u0026gt; - \\langle \\vec{X},\\beta\\rangle\\ \\ \\bigg|\\ \\ \\vec{X}\\bigg) = P(\\epsilon \u0026lt; \\langle \\vec{X},\\beta\\rangle\\ | \\vec{X})\r\\]\rSince \\(\\epsilon \\sim \\mathcal{N}(0,1)\\) this last probability is equal to \\(\\Phi(\\langle \\vec{X},\\beta\\rangle)\\) where \\(\\Phi\\) denotes the standard normal CDF. This derives the probit model.\nBefore we proceed, notice 2 points which we won’t dwell on:\n\rIf the variance of \\(Y^*\\) had been \\(\\sigma^2 \\ne 1\\) then the value of \\(\\sigma\\) would not be able to be estimated from data without knowing \\(\\beta\\) since \\(P(Y^* \u0026gt; 0 |\\vec{X}) = P(Y^*/\\sigma \u0026gt; 0 | \\vec{X})\\).\rIf the distributional relationship between \\(Y\\) and \\(\\vec{X}\\) had been such that the error term \\(\\epsilon\\) where a logistic random variable, instead of a normal one, then the censored problem would have become logistic regression.\r\rFor the regression itself we assume that we have a data set \\(\\{ (y_i, \\vec{x}_i)\\}_{i = 1}^N\\) consisting of samples generated independently of one another from a fixed multivariate distribution for \\((Y, \\vec{X})\\) (i.e. we assume our data was sampled IID).\n\rFitting Probit Regression via EM\rSince probit regression arises from a censored normal OLS model, and since OLS is relatively easy to fit, probit regression is an excellent candidate for applying Expectation Maximization for fitting. A small difference will be that all of the probability densities involved will be conditional on the observed covariates \\(\\{\\vec{x}_i\\}_{i = 1}^N\\) since regression is a conditional relationship.\nLet’s recall the standard EM algorithm for the case of the regression problem above:\n\rStep 1: Let \\(m = 0\\). Make an initial estimate \\(\\beta_m\\) for \\(\\beta\\).\n\rStep 2: Given the observed data \\(\\{(y_i, \\vec{x}_i)\\}_{i = 1}^N\\) and pretending for the moment that our current guess \\(\\beta_m\\) is correct, construct the conditional probability distribution \\(p(\\{y^*_i\\}\\ \\ |\\ \\ \\{(y_i, \\vec{x}_i)\\},\\ \\beta_m)\\) of the hidden data \\(\\{Y^*_i\\}\\) given all known information.\n\rStep 3: Using the distribution \\(p(\\{y^*_i\\}\\ \\ |\\ \\ \\{(y_i, \\vec{x}_i)\\},\\ \\beta_m)\\) construct the following estimator/approximation of the desired log-likelihood \\(\\log(p(\\{Y^*_i\\} \\ | \\ \\beta, \\{\\vec{x}_i\\}))\\) for arbitrary values of \\(\\beta\\):\n\r\r\\[\rQ(\\beta | \\beta_m) \\ := \\ \\text{E}_{\\{Y^*_i\\}\\ \\ |\\ \\ \\{(Y_i=y_i,\\ \\vec{X}_i=\\vec{x}_i)\\},\\ \\beta_m} \\big[ \\log(p(\\{Y^*_i\\} \\ | \\ \\beta, \\{\\vec{x}_i\\})) \\big] \\]\r\\[\r= \\int_{\\mathcal{Y^*}} \\log(p(\\{y^*_i\\} \\ | \\ \\beta, \\{\\vec{x}_i\\})) \\ p(\\{y^*_i\\}\\ |\\ \\{(y_i, \\vec{x}_i)\\}, \\beta_m) \\ dy_1^*...dy^*_N \\]\n\rStep 4: Set \\(\\beta_{m+1}\\) equal to a value of \\(\\beta\\) that maximizes the current approximation \\(Q(\\beta|\\beta_m)\\) of \\(\\log(p(\\{Y^*_i\\} \\ | \\ \\beta, \\{\\vec{x}_i\\}))\\).\n\rStep 5: Return to step 2 and repeat until some stopping criteria is met.\n\r\rThese formulas may seem difficult at the moment because they are in such a general form. As we specify things for our particular problem things will become more concrete. Now because \\(Y^*|\\vec{X}\\sim \\mathcal{N}(\\ \\langle \\vec{X} , \\beta\\rangle \\ ,\\ 1)\\) is a normal linear regression relationship we have\r\\[\rp(\\{Y^*_i\\} \\ | \\ \\beta, \\{\\vec{x}_i\\}) = \\frac{1}{(2\\pi)^{N/2}}e^{\\sum_{i=1}^N-\\frac{1}{2}\\big(Y^*_i - \\langle \\vec{x}_i , \\beta\\rangle\\big)^2}\r\\]\nHence\r\\[\r\\log(p(\\{Y^*_i\\} \\ | \\ \\beta, \\{\\vec{x}_i\\})) = const -\\frac{1}{2} \\sum_{i=1}^N\\big(Y^*_i - \\langle \\vec{x}_i , \\beta\\rangle\\big)^2\r\\]\nand so the \\(Q\\)-function is\r\\[\rQ(\\beta | \\beta_m) \\ = \\ \\text{E}_{\\{Y^*_i\\}\\ \\ |\\ \\ \\{(Y_i=y_i,\\ \\vec{X}_i=\\vec{x}_i)\\},\\ \\beta_m} \\bigg[ -\\frac{1}{2} \\sum_{i=1}^N\\big(Y^*_i - \\langle \\vec{x}_i , \\beta\\rangle\\big)^2 \\bigg] + const\r\\]\nSince the data samples are assumed IID we can apply the representation we derived in the first post in the series where instead of taking the expectation over all samples, we sum over the expectations of each individual sample:\n\\[\rQ(\\beta | \\beta_m) \\ = \\ const - \\frac{1}{2}\\sum_{i = 1}^N\\text{E}_{Y^*_i\\ \\ |\\ \\ Y_i=y_i,\\ \\ \\vec{X}_i=\\vec{x}_i,\\ \\ \\beta_m} \\bigg[\\big(Y^*_i - \\langle \\vec{x}_i , \\beta\\rangle\\big)^2 \\bigg]\r\\]\nNote that in the EM algorithm we do not actually need to evaluate this function. Instead in step 4 we simply want to find the value of \\(\\beta\\) that maximizes it. In addition, as we discussed in the first post, if we wanted to incorporate a prior distribution \\(p(\\beta)\\) on \\(\\beta\\) for the purpose of regularization we would replace the problem of maximizing \\(Q(\\beta|\\beta_m)\\) by maximizing \\(Q(\\beta|\\beta_m) + \\log(p(\\beta))\\) instead. For the purpose of \\(L^2\\)-regularization we could simply take \\(\\beta \\sim \\mathcal{N}(\\vec{0}, \\frac{1}{\\lambda})\\). In that case\r\\[\rQ(\\beta|\\beta_m) + \\log(p(\\beta)) = \\ const - \\frac{1}{2}\\sum_{i = 1}^N\\text{E}_{Y^*_i\\ \\ |\\ \\ Y_i=y_i,\\ \\ \\vec{X}_i=\\vec{x}_i,\\ \\ \\beta_m} \\bigg[\\big(Y^*_i - \\langle \\vec{x}_i , \\beta\\rangle\\big)^2 \\bigg] - \\frac{\\lambda}{2}\\langle \\beta, \\beta\\rangle\r\\]\n(the \\(const\\) may now depend on \\(\\lambda\\) which we always treat as a constant). We will focus on maximizing this regularized function, knowing that we can simply let \\(\\lambda = 0\\) to remove the regularization. At the maximizing point we need the gradient with respect to \\(\\beta\\) to equal 0:\r\\[\r\\nabla_{\\beta} \\ \\big(Q(\\beta|\\beta_m) + \\log(p(\\beta))\\big) = 0\r\\]\n(where the \\(0\\) represents the zero vector in \\(\\mathbb{R}^p\\)). Interchanging gradients first with the summation, then with the expectation (since all random variables have nice distributions) gives\r\\[\r0 = \\sum_{i = 1}^N\\text{E}_{Y^*_i\\ \\ |\\ \\ Y_i=y_i,\\ \\ \\vec{X}_i=\\vec{x}_i,\\ \\ \\beta_m} \\bigg[\\big(Y^*_i - \\langle \\vec{x}_i , \\beta\\rangle\\big)\\vec{x}_i \\bigg] - \\lambda \\beta\r\\]\r\\[\r= \\sum_{i = 1}^N\\text{E}_{Y^*_i\\ \\ |\\ \\ Y_i=y_i,\\ \\ \\vec{X}_i=\\vec{x}_i,\\ \\ \\beta_m} \\big[Y^*_i\\big]\\vec{x}_i - \\sum_{i = 1}^N\\langle \\vec{x}_i , \\beta\\rangle\\vec{x}_i - \\lambda \\beta\r\\]\nLet \\(X\\in\\mathbb{R}^{N\\times p}\\) be an \\(N\\times p\\) matrix whose \\(i\\)-th row is \\(\\vec{x}_i\\), and let \\(Z\\in \\mathbb{R}^{N\\times 1}\\) be a vector with \\(i\\)-th component \\(z_i = \\text{E}_{Y^*_i\\ \\ |\\ \\ Y_i=y_i,\\ \\ \\vec{X}_i=\\vec{x}_i,\\ \\ \\beta_m} \\big[Y^*_i\\big]\\). Then in matrix notation the above becomes\r\\[\r0 = X^TZ - X^TX\\beta - \\lambda\\beta \\\\= X^TZ - (X^TX\\beta + \\lambda I)\\beta\r\\]\nThis looks very familiar! It looks exactly like the normal equations of OLS if the target variable had been \\(Z\\). The value of \\(Z = \\big(\\text{E}_{Y^*_i\\ \\ |\\ \\ Y_i=y_i,\\ \\ \\vec{X}_i=\\vec{x}_i,\\ \\ \\beta_m} \\big[Y^*_i\\big]\\big)_{i=1}^N\\) is just the value of \\(Y^*\\) we would guess given the values \\(y_i\\) of the censored variable and \\(\\vec{x}_i\\) of the covariates. Basically EM is telling us to impute a conditional average for the missing data \\(Y^*\\), fit OLS, and repeat. Solving for \\(\\beta\\) gives\r\\[\r\\beta_{m+1} = (X^TX + \\lambda I)^{-1}X^TZ\r\\]\rThis can be implemented once we know the value of \\(Z\\). Since \\(Z_i = \\text{E}_{Y^*_i\\ \\ |\\ \\ Y_i=y_i,\\ \\ \\vec{X}_i=\\vec{x}_i,\\ \\ \\beta_m} \\big[Y^*_i\\big]\\) then this is just the mean of a truncated normal distribution:\r\\[\r\\text{E}_{Y^*_i\\ \\ |\\ \\ Y_i=1,\\ \\ \\vec{X}_i=\\vec{x}_i,\\ \\ \\beta_m} \\big[Y^*_i\\big] = \\langle \\vec{x}_i , \\beta_m\\rangle + \\frac{\\phi(\\langle \\vec{x}_i , \\beta_m\\rangle)}{1 - \\Phi(-\\langle \\vec{x}_i , \\beta_m\\rangle)}\r\\]\n\\[\r\\text{E}_{Y^*_i\\ \\ |\\ \\ Y_i=0,\\ \\ \\vec{X}_i=\\vec{x}_i,\\ \\ \\beta_m} \\big[Y^*_i\\big] = \\langle \\vec{x}_i , \\beta_m\\rangle - \\frac{\\phi(\\langle \\vec{x}_i , \\beta_m\\rangle)}{\\Phi(-\\langle \\vec{x}_i , \\beta_m\\rangle)}\r\\]\rwhere \\(\\phi\\) and \\(\\Phi\\) are the standard normal PDF and CDF respectively. Therefore, we can summarize the EM algorithm for Probit Regression as:\n\rStep 1: Let \\(m = 0\\). Make an initial estimate \\(\\beta_m\\) for \\(\\beta\\).\rStep 2: Impute the censored data according to\r\r\\[\rz_i =\r\\begin{cases}\r\\langle \\vec{x}_i , \\beta_m\\rangle + \\frac{\\phi(\\langle \\vec{x}_i , \\beta_m\\rangle)}{1 - \\Phi(-\\langle \\vec{x}_i , \\beta_m\\rangle)}, \u0026amp; \\text{if} \\ \\ y_i = 1 \\\\\r\\langle \\vec{x}_i , \\beta_m\\rangle - \\frac{\\phi(\\langle \\vec{x}_i , \\beta_m\\rangle)}{\\Phi(-\\langle \\vec{x}_i , \\beta_m\\rangle)}, \u0026amp; \\text{if} \\ \\ y_i = 0\r\\end{cases}\r\\]\n\rStep 3: Solve the regularized OLS problem to update \\(\\beta\\):\r\r\\[\r\\beta_{m+1} = (X^TX + \\lambda I)^{-1}X^TZ\r\\]\n\rStep 4: Return to step 2 and repeat until some stopping criteria is met.\r\r\rImplementing in C++ using Eigen\rThe algorithm above is easily implementable in R, Numpy, Matlab, etc., but for fun we’ll implement it in C++ using the Eigen linear algebra library. We do this in Rmarkdown using the RcppEigen package in R.\nFirst we include the necessary header files. Here RcppEigen.h includes the Eigen library itself, as well as all the necessary boilerplate code of Rcpp to integrate Eigen (and C++) with R.\n#include \u0026lt;RcppEigen.h\u0026gt;\r#include \u0026lt;algorithm\u0026gt;\r#include \u0026lt;limits\u0026gt;\r// [[Rcpp::depends(RcppEigen)]]\rusing namespace Eigen;\rNext we define two functions that will be needed in computing the vector \\(Z\\), whose computation requires the normal distribution’s PDF and CDF. We’ll use R’s own built-in functions dnorm and pnorm. These functions are written in C or Fortran (and hence can be called from any language with a C interface) and are very well tested. So instead of rolling our own versions we may as well use R’s.\n// [[Rcpp::export]]\rdouble positive(const double mu) {\rdouble num = R::dnorm(mu, 0, 1, false);\rdouble den = 1 - R::pnorm(-mu, 0, 1, true, false);\rreturn mu + num/den;\r}\r// [[Rcpp::export]]\rdouble negative(double mu)\r{\rdouble num = R::dnorm(mu, 0, 1, false);\rdouble den = R::pnorm(-mu, 0, 1, true, false);\rreturn mu - num/den;\r}\rNext we want a function that actually computes the \\(Z\\) vector, given \\(X\\) and \\(\\beta_m\\). We could use some of Eigen’s nifty nullary expressions, but a simple for-loop with a ternay conditional will do. We also create a wrapper function so that we can test from R:\nVectorXd impute(const MatrixXd\u0026amp; X,\rconst VectorXd\u0026amp; beta,\rconst VectorXi\u0026amp; Y)\r{\rVectorXd Z = X * beta;\r// If Y(i) is non-zero use the function // positive, else use negative\rfor(int i = 0; i != Z.size(); ++i)\rZ(i) = (Y(i) == (int)1) ? (positive(Z(i))) : (negative(Z(i)));\rreturn Z;\r}\r// A wrapper function to test from R\r// [[Rcpp::export]]\rVectorXd impute_test(const Map\u0026lt;MatrixXd\u0026gt; X,\rconst Map\u0026lt;VectorXd\u0026gt; beta,\rconst Map\u0026lt;VectorXi\u0026gt; Y)\r{\rreturn impute(X, beta, Y);\r}\rComparing to an R implementation is trivial:\nX = matrix(rnorm(100*10), ncol = 10)\rbeta = matrix(rnorm(10), ncol = 1)\rY = matrix(sample(c(0L,1L), size = 100, replace = T), ncol = 1)\r# Using the C++ implementation\rZ.cpp = impute_test(X, beta, Y)\r# Building one in in R\rimputeR = function(X, beta, Y)\r{\rpositiveR = function(Z){Z + dnorm(Z)/(1-pnorm(-Z))}\rnegativeR = function(Z){Z - dnorm(Z)/pnorm(-Z)}\rZ = X %*% beta\rreturn(ifelse((Y == 1L), positiveR(Z), negativeR(Z)))\r}\rZ.r = imputeR(X, beta, Y)\r# Checking range of values\rprint(summary(Z.cpp - Z.r))\r## V1 ## Min. :-5.773e-15 ## 1st Qu.:-2.776e-17 ## Median : 0.000e+00 ## Mean : 4.119e-16 ## 3rd Qu.: 0.000e+00 ## Max. : 3.375e-14\rNot bad. Next we need a function to compute (regularized) least squares. For the solution we use the normal equations. According to the Eigen tutorial on the matter the normal equations are the fastest but least numerically stable option. For us this is good enough. Again we create a small wrapper to test from R:\nVectorXd RLS(const VectorXd\u0026amp; Z, const MatrixXd\u0026amp; X, const double lambda = 0.0)\r{\r// Creating an identity matrix\rMatrixXd lambda_eye = lambda * MatrixXd::Identity(X.cols(), X.cols());\r// Using (regularized) normal equations\rif(lambda \u0026gt;= std::numeric_limits\u0026lt;double\u0026gt;::min())\rreturn (X.transpose() * X + lambda_eye).ldlt().solve(X.transpose() * Z);\rreturn (X.transpose() * X).ldlt().solve(X.transpose() * Z);\r}\r// [[Rcpp::export]]\rVectorXd RLS_test(const Map\u0026lt;VectorXd\u0026gt; Z, const Map\u0026lt;MatrixXd\u0026gt; X,\rdouble lambda = 0.0)\r{\rreturn RLS(Z, X, lambda);\r}\rTesting in R:\nset.seed(1234)\rX = matrix(rnorm(100*10), ncol = 10)\rbeta = matrix(rnorm(10), ncol = 1)\rZ = X %*% beta + matrix(rnorm(100), ncol = 1)\rbeta_hat.r = lm.fit(X, Z, method = \u0026quot;qr\u0026quot;)$coefficients\rbeta_hat.cpp = RLS_test(Z, X, 0)\rprint(data.frame(beta = beta, beta_hat.r = beta_hat.r, beta_hat.cpp = beta_hat.cpp))\r## beta beta_hat.r beta_hat.cpp\r## x1 -1.2053334 -1.2721727 -1.2721727\r## x2 0.3014667 0.2774444 0.2774444\r## x3 -1.5391452 -1.5961346 -1.5961346\r## x4 0.6353707 0.5781086 0.5781086\r## x5 0.7029518 0.8563414 0.8563414\r## x6 -1.9058829 -2.0154512 -2.0154512\r## x7 0.9389214 0.8108957 0.8108957\r## x8 -0.2244921 -0.3825277 -0.3825277\r## x9 -0.6738168 -0.7562696 -0.7562696\r## x10 0.4457874 0.4209543 0.4209543\rprint(summary(beta_hat.cpp - beta_hat.r))\r## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -8.882e-16 -6.800e-16 -5.551e-17 4.996e-17 3.053e-16 2.220e-15\rNot bad at all. Note that R’s very powerful lm.fit function uses QR decomposition to solve the least squares problem. This method is a bit slower in principle than the \\(LDL^T\\) decomposition we used for the normal equations above, but it’s also higher quality numerically.\nAs for a test with a non-trivial regularization constant:\nlambda = 15\rbeta_hat_reg.r = solve(t(X) %*% X + lambda*diag(10), t(X) %*% Z)\rbeta_hat_reg.cpp = RLS_test(Z, X, lambda)\rprint(data.frame(beta = beta, beta_hat_reg.r = beta_hat_reg.r, beta_hat_reg.cpp = beta_hat_reg.cpp))\r## beta beta_hat_reg.r beta_hat_reg.cpp\r## 1 -1.2053334 -1.1372786 -1.1372786\r## 2 0.3014667 0.2299293 0.2299293\r## 3 -1.5391452 -1.3128364 -1.3128364\r## 4 0.6353707 0.4366746 0.4366746\r## 5 0.7029518 0.7691213 0.7691213\r## 6 -1.9058829 -1.7122424 -1.7122424\r## 7 0.9389214 0.7415632 0.7415632\r## 8 -0.2244921 -0.2756274 -0.2756274\r## 9 -0.6738168 -0.5224541 -0.5224541\r## 10 0.4457874 0.4061769 0.4061769\rprint(summary(beta_hat_reg.cpp - beta_hat_reg.r))\r## V1 ## Min. :-7.772e-16 ## 1st Qu.:-1.110e-16 ## Median : 0.000e+00 ## Mean :-2.776e-17 ## 3rd Qu.: 2.082e-16 ## Max. : 3.331e-16\rVery good. Again, we see that the regularized least squares estimates are biased away from the true values, and towards the 0 vector.\nNow we bring it all together into one algorithm:\n// [[Rcpp::export]]\rVectorXd Probit(const Map\u0026lt;VectorXi\u0026gt; Y, const Map\u0026lt;MatrixXd\u0026gt; X, double lambda = 0.0,\rint num_iter = 100)\r{\r// Making sure Lambda is non-negative;\rlambda = std::max(lambda, 0.0);\r// Making sure the number of rows of X is the // same as the number of rows of Y\rassert(Y.size() == X.rows());\r// Initialize beta to 0 values\rVectorXd beta = VectorXd::Zero(X.cols());\r// Iteration\rfor(int i = 0; i \u0026lt; num_iter; ++i)\r{\r// Impute the Z vector\rVectorXd Z = impute(X, beta, Y);\r// Solve (regularized) Least Squares beta = RLS(Z, X, lambda);\r}\rreturn beta;\r}\rBelow we carry out a comparison of the base R implementation of (unregularized) probit regression against our implementation.\nlibrary(MASS)\rN = 10000\rp = 4\rset.seed(1234)\rS = matrix(rnorm(p*p), ncol = p)\rS = t(S) %*% S\rX = MASS::mvrnorm(n = N, mu = rep(0.0, times = p), Sigma = S)\rbeta = matrix((1:p)/2, ncol = 1)\rZ = X %*% beta + matrix(rnorm(N))\rY = as.integer(Z \u0026gt; 0)\rsystem.time(probit.cpp100 \u0026lt;- Probit(Y, X, 0.0, 100))\r## user system elapsed ## 0.21 0.00 0.20\rsystem.time(probit.cpp10000 \u0026lt;- Probit(Y, X, 0.0, 10000))\r## user system elapsed ## 21.33 0.00 21.33\rsystem.time(probit.glm \u0026lt;- glm(Y ~ X - 1, family = binomial(link = \u0026quot;probit\u0026quot;))$coefficients)\r## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred\r## user system elapsed ## 0.07 0.00 0.06\rprint(data.frame(beta = beta, Cpp_100_iter = probit.cpp100,\rCpp_10000_iter = probit.cpp10000,\rR = probit.glm))\r## beta Cpp_100_iter Cpp_10000_iter R\r## X1 0.5 0.4128896 0.5002905 0.5002889\r## X2 1.0 0.8632397 0.9845270 0.9845285\r## X3 1.5 1.2932036 1.5056988 1.5056998\r## X4 2.0 1.7173029 1.9814520 1.9814547\rWe see the base R version is much faster, and converges much more quickly. Note, this is not due to weak compiler flags on our part. A local Makevars file in Documents/.R overrides the default R build flags to use the optimizations -O3 -march=native.\nNo, instead glm.fit uses iteratively reweighted least squares (IRLS) to fit the model, not EM as can be seen in the source code. So EM is not a very fast algorithm to fit probit models. In the future we’ll implement IRLS in Eigen (or Fortran, or Julia).\n\r","date":1596240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596240000,"objectID":"81bf02a3792288cf38450c4ef30ae89c","permalink":"/post/005_em2_probit/main/","publishdate":"2020-08-01T00:00:00Z","relpermalink":"/post/005_em2_probit/main/","section":"post","summary":"Introduction\rIn the first post in this series we discussed Expectation Maximization (EM) type algorithms. In the post prior to this one we discussed regularization and showed how it leads to a bias-variance trade off in OLS models.","tags":["r","rcpp","eigen","c++","expectation maximization","em algorithm","em","regularization","machine learning","statistical learning","bias variance tradeoff"],"title":"Expectation Maximization, Part 2: Fitting Regularized Probit Regression using EM in C++","type":"post"},{"authors":null,"categories":["R","Theory"],"content":"\rIntroduction\rMany newcomers to machine learning know about regularization, but they may not understand it yet. In particular, they may not know why regularization has that name. In this post we discuss the numerical and statistical significance of regularization methods in machine learning and more general statistical models. We’ll try to introduce why one may want to use regularization methods in the first place and how to interpret the fitted model from a statistical point of view.\nThe post will be long because there are a lot of cute nooks and crannies, and we’ll assume you know your linear algebra. However, if you already know what an inner product is then we think this post will be worth your time.\n\rMatrices and Linear Ill-Posed Problems\rSuppose that we have a matrix \\(A\\in \\mathbb{R}^{N \\times p}\\), a vector \\(y\\in \\mathbb{R}^N\\), and that we seek a vector \\(\\beta\\in\\mathbb{R}^p\\) such that \\(A\\beta = y\\). How would one solve this problem? One answer might be to simply apply the inverse matrix to both sides of the equation: \\(\\beta = A^{-1}y\\). However, there are three problems with this:\nA matrix inverse \\(A^{-1}\\) may not exist.\rEven if the matrix inverse exists it can be extremely expensive to calculate this inverse and apply the result to \\(y\\).\rEven if we are somehow able to calculate \\(A^{-1}y\\) the solution may not be very stable. Small numerical changes in either \\(A\\) or \\(y\\) may lead to large changes in the solution \\(\\beta\\).\r\rIssue 2 above is not really a problem in the sense that one should never really need to find \\(A^{-1}\\) to compute \\(A^{-1}y\\). Instead the most efficient numerical algorithms typically compute \\(A^{-1}y\\) by using special factorizations of \\(A\\), such as QR decomposition.\nThe other two issues are very important and are inextricably linked to each other and to regularization in machine learning.\n\rIssue 3 means just what is says: that the solution \\(\\beta\\) may change a lot if the known data \\(A\\) and/or \\(y\\) only change a little.\n\rIssue 1 means that the matrix is not invertible. A matrix that is not invertible is called singular. A matrix that is invertible is usually called nonsingular, but a less common synonym is regular and this is where the name regularization comes from. When a matrix is singular it means that the problem \\(A\\beta = y\\) may have either no solution at all or have at least 2 distinct solutions.\n\r\rAny one of these issues being true means that the linear problem \\(A\\beta = y\\) is ill-posed in the sense that it violates Hadamard’s conditions for a well-posed problem. To be well-posed:\nA problem must have a solution\rThe solution must be unique\rThe solution’s behavior must be stable/continuous with respect to the data\r\rThese conditions are of extreme practical importance. They basically define what it means for a problem to be solvable in practice. In the case of the linear algebra problem above regularization means “making the matrix regular” so that these conditions will hold true on the regularized problem. That’s where the name comes from.\nOk, cool but why are these conditions important to ML or statistics? Consider the case of Maximum Likelihood Estimation (MLE) of a parametric model (although the lesson applies more generally):\nIn MLE we estimate a model’s unknown parameters by maximizing the log-likelihood. If no such maximizing values of the parameters can be found then the optimization problem does not have a solution and we can not obtain estimates for the unknown parameters to begin with! So, mirroring the first Hadamard condition, we require a maximizer to exist.\rNon-Bayesian statistical models naturally assume that a single fixed set of parameters exists that specifies the relevant distributions. If MLE gives multiple sets of parameters that maximize the likelihood (as happens in the presence of multiple local maxima) we may have no way to tell which maximizer is the one that estimates the actual parameters the best! So, mirroring the second Hadamard condition, we require the maximizer to be unique.\rStatistical models assume that data is in part random and so is subject to changes. If the estimated values of the parameters change a lot when the data changes a little then it’s impossible to tell when the MLE estimated parameters are in fact good estimates of the true parameters and when they are not! So, mirroring the third Hadamard condition, we require the maximizer to be stable with respect to changes in the data used for the fit.\r\rRegularization is one way to change the problem so that these conditions are met.\n\rSome examples\rOk, let’s look at some examples!\nShifting the eigenvalues of a Symmetric Matrix\rSuppose we are asked to solve the linear inverse problem from above \\(A\\beta = y\\), but that this time \\(A\\in \\mathbb{R}^{N\\times N}\\) is a symmetric matrix. The spectral theorem for symmetric matrices tells us that \\(A\\) can be represented as\n\\[\rA = QDQ^T\r\\]\rwhere \\(Q\\) is an orthogonal matrix and \\(D\\) is a diagonal matrix. Moreover, the columns of \\(Q\\) are the eigenvectors of \\(A\\), and the diagonal elements of \\(D\\) are the corresponding (real) eigenvalues. Here’s a proof if you care for it.\nThis representation shows us exactly what the theoretical difficulty is in the inverse problem. Inverting \\(Q\\) is easy. Indeed orthogonal matrices are always invertible, with the inverse given by the transpose: \\(Q^{-1} = Q^T\\). The geometric significance of orthogonal matrices comes from the fact (basically their definition) that they preserve the inner product of vectors: If we denote the inner product by \\(\\langle \\cdot,\\cdot\\rangle\\) then for any \\(x,y \\in R^N\\)\n\\[\r\\langle x, y \\rangle = \\langle Qx, Qy \\rangle\r\\]\rThus (using the definition of the transpose) \\(\\langle x, y \\rangle = \\langle Q^TQx, y \\rangle\\). Since this holds for any \\(y\\), then \\(x = Q^TQx\\) for all \\(x\\). Since this holds for all \\(x\\) then \\(Q^TQ = I\\) and so \\(Q^T\\) is the inverse of \\(Q\\).\nNo, the difficulty is simply in inverting the diagonal matrix \\(D = \\text{diag}(\\sigma_1, \\sigma_2, ..., \\sigma_N)\\). If none of the eigenvalues \\(\\sigma_i\\) are \\(0\\) then \\(D^{-1} = \\text{diag}(\\sigma_1^{-1}, \\sigma_2^{-1}, ..., \\sigma_N^{-1})\\). In this case there isn’t any direction that \\(D\\) (and hence \\(A\\)) squashes into \\(0\\). However, if some of the \\(\\sigma_i\\)’s are \\(0\\) then we can not invert \\(D\\) and the problem will fail to satisfy at least one of the first 2 Hadamard conditions. Even if none of the \\(\\sigma_i\\)’s are exactly \\(0\\), some may be numerically very close to \\(0\\) in comparison to the others. In that case the value of their reciprocals may be enormously large and may lead to numerical instability in the problem, violating the 3rd Hadamard condition. This would be a big problem in practice because computers hate mixing floating point numbers that are drastically different in size.\nTo address this issue we note that we can shift the eigenvalues of \\(A\\) by adding a multiple of an identity matrix:\n\\[\rA \\to A + \\lambda I\r\\]\rIf \\(\\sigma\\) is an eigenvalue of \\(A\\) then \\(\\sigma+\\lambda\\) is an eigenvalue of \\(A+\\lambda I\\). This is because every vector is an eigenvector of \\(I\\): If \\(Av = \\sigma v\\) then trivially \\(\\lambda Iv = \\lambda v\\), so adding gives \\((A+\\lambda I)v = (\\sigma + \\lambda)v\\). This can also be seen form the representation above:\r\\[\rA + \\lambda I = QDQ^T + \\lambda QQ^T = Q(D + \\lambda I)Q^T = Q\\tilde{D}Q^T\r\\]\rwhere \\(\\tilde{D}= \\text{diag}(\\sigma_1 + \\lambda, \\sigma_2 + \\lambda, ..., \\sigma_N + \\lambda)\\). Therefore, if we choose \\(\\lambda \u0026gt; \\min\\{\\sigma_1, \\sigma_2, ..., \\sigma_N\\}+ \\delta\\) for some \\(\\delta \u0026gt; 0\\), then all the shifted eigenvalues satisfy \\(\\sigma_i + \\lambda \u0026gt; \\delta \u0026gt; 0\\) and the new shifted problem\n\\[\r(A+\\lambda I)x = y\r\\]\rwill be solvable with solution given by\r\\[\rx = Q(D + \\lambda I)^{-1}Q^Ty\r\\]\rIf \\(\\lambda\\) is sufficiently large this inverse will exist and will be numerically stable (all of the eigenvalues will have been shifted away from 0).\nMaking the change \\(A \\to A + \\lambda I\\) regularized the problem into one that satisfied Hadamard’s conditions, which is fundamentally the point of regularization. The change we made was essentially to replace the \\(A^{-1}\\) with the approximation \\((A+\\lambda I)^{-1}\\), but we could have used other approximations as well, for example partial sums of the Neumann Series Expansion of the \\(A^{-1}\\). Regardless, the general principle illustrated above is basically to replace one problem by an approximate problem that does not suffer the same existence/stability issues.\n\rRegularization as a perturbation of an invertible matrix\rAbove we regularized the ill-posed problem \\(A\\beta = y\\) by replacing it with the problem \\((A+\\lambda I)x = y\\). Let’s go a bit deeper with this process.You may skip this section on your first read.\nDividing by \\(\\lambda\\), the problem \\((A+\\lambda I)x = y\\) is equivalent to the problem\n\\[\r(\\epsilon A+I)x = \\epsilon y\r\\]\rwhere \\(\\epsilon := \\frac{1}{\\lambda}\\). When \\(\\lambda\\) is large \\(\\epsilon\\) is small, and vice versa. Hence for large \\(\\lambda\\) the matrix \\(\\epsilon A+I\\) can be seen as a small perturbation from the identity matrix \\(I\\).\nNow because \\(I\\) is invertible then for a small enough \\(\\epsilon\\) (and hence for a large enough \\(\\lambda\\)) the preturbed matrix \\(\\epsilon A+I\\) is also invertible! Why? That’s a great question! The previous section gave one proof, but there are some much nicer ways to see why:\nProof: Consider the function\r\\[\r\\det:\\mathbb{R}^{N\\times N} \\to \\mathbb{R}\r\\]\rthat maps a matrix to it’s determinant. Because the space \\(\\mathbb{R}^{N\\times N}\\) of \\(N\\times N\\) matrices is just the Euclidean inner product space \\(\\mathbb{R}^{N^2}\\) with some extra algebraic structure, and because \\(\\det(A)\\) is a polynomial function of the elements of a matrix \\(A\\), \\(\\det\\) is a continuous function on \\(\\mathbb{R}^{N\\times N}\\).\nBy Cramer’s Rule, a matrix \\(A\\) is invertible if and only if \\(\\det(A) \\ne 0\\). Because \\(\\det\\) is a continuous function on \\(\\mathbb{R}^{N\\times N}\\) then the set of invertible matrices is an open subset of \\(\\mathbb{R}^{N\\times N}\\)! Hence for every invertible matrix \\(L\\in\\mathbb{R}^{N\\times N}\\) and every arbitrary matrix \\(A\\in\\mathbb{R}^{N\\times N}\\) there exists an \\(\\epsilon_0 \u0026gt; 0\\) such that for all \\(\\epsilon \u0026lt; \\epsilon_0\\) the matrix \\(\\epsilon A+L\\) is invertible. QED\nThere’s a version of the theorem in Banach spaces, but we don’t need it.\nNoticed that the only thing we needed about the matrix \\(I\\) in the above proof was that it was invertible. Therefore, we never needed to restrict attention to just the identity matrix \\(I\\), but could have used any invertible matrix to regularize the problem:\n\\[\r(A+\\lambda L)x = y\r\\]\nwhere \\(L\\) is any convenient invertible matrix. Below, where we regularize OLS, we are not restricted to using the identity matrix \\(I\\) to regularize, but can use any invertible symmetric matrix (preferably one that is positive definite so that a minimizer continues to exist).\n\r\\(L^2\\)-regularization of OLS\rWith this example we begin moving towards the statistical part of the post. One of the most widely known examples of regularization is what is often called \\(L^2\\)-regularization, or Tikhonov regularization of Ordinary Least Squares.\nSuppose \\(Y\\) is a real valued random variable and \\(\\vec{X}\\) is a random vector with values in \\(\\mathbb{R}^p\\). Suppose that we have the conditional relationship\n\\[\rY \\ \\ | \\ \\ \\vec{X} \\sim \\mathcal{N}(\\ \\langle \\vec{X} , \\beta\\rangle \\ ,\\ \\sigma^2)\r\\]\nwhere \\(\\mathcal{N}(\\mu, \\sigma^2)\\) denotes the univariate normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\). Here (and everywhere else) the symbol \\(\\langle v,w\\rangle\\) represents the inner product of two vectors \\(v\\) and \\(w\\). This is the most natural probability model that leads to linear regression. In practice the parameters \\(\\beta\\) and \\(\\sigma\\) that specify this conditional distribution are unknown and it is desired that they be estimated from data.\nIn this canonical situation we assume that we have a data set \\(\\{ (Y_i, \\vec{X}_i)\\}_{i = 1}^N\\) consisting of samples generated independently of one another from a fixed multivariate distribution for \\((Y, \\vec{X})\\) (i.e. we assume our data was sampled IID). To fit the unknown parameters we use MLE. We may choose to use the conditional density \\(p(Y|\\vec{X})\\) in the likelihood and this would make it conditional MLE. Or we may choose the unconditional multivariate density \\(p(Y, \\vec{X})\\). However, if we assume that the marginal distribution of \\(\\vec{X}\\), (i.e. \\(p(\\vec{X})\\)), does not depend on either \\(\\beta\\) or \\(\\sigma\\) then because \\(p(Y,\\vec{X}) = p(Y|\\vec{X})p(\\vec{X})\\) building the likelihood using either \\(p(Y|\\vec{X})\\) or \\(p(Y,\\vec{X})\\) will lead to the same maximization problem because they differ by a constant factor (constant in \\(\\beta\\) and \\(\\sigma\\) that is). So we will use the conditional density \\(p(Y|\\vec{X})\\).\nBecause the data is assumed to be generated IID then the full likelihood of the data is\n\\[\r\\mathcal{L}(\\beta, \\sigma\\ |\\ \\{ (Y_i, \\vec{X}_i)\\}) = \\prod_{i = 1}^N p(Y_i|\\vec{X}_i) = \\prod_{i=1}^N\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\big(\\frac{Y_i - \\langle \\vec{X}_i , \\beta\\rangle}{\\sigma}\\big)^2} = \\frac{1}{(\\sigma^22\\pi)^{N/2}}e^{\\sum_{i=1}^N-\\frac{1}{2}\\big(\\frac{Y_i - \\langle \\vec{X}_i , \\beta\\rangle}{\\sigma}\\big)^2}\r\\]\rBecause the function \\(f(x) := -\\log(x)\\) is decreasing we may instead minimize the negative of the log of this expression:\r\\[\r-\\log(\\mathcal{L}(\\beta,\\sigma\\ |\\ \\{ (Y_i, \\vec{X}_i)\\})) = \\frac{N}{2}\\log(\\sigma^22\\pi) + \\frac{1}{2\\sigma^2}\\sum_{i=1}^N\\bigg(Y_i - \\langle \\vec{X}_i , \\beta\\rangle\\bigg)^2\r\\]\rWe first minimize with respect to \\(\\beta\\) as this is necessary to do first before finding the minimizing value of \\(\\sigma\\). To do this we need to minimize the only term that depends on \\(\\beta\\), namely the sum of squares \\(SSE(\\beta) := \\sum_{i=1}^N\\bigg(Y_i - \\langle \\vec{X}_i , \\beta\\rangle\\bigg)^2\\) (hence Least Squares regression).\nA geometric interlude\rBefore we do that, let’s think about what the expression \\(SSE(\\beta)\\) is. The term \\(\\langle \\vec{X}_i , \\beta\\rangle\\) is linear in the unknowns \\(\\beta\\), and hence so is \\(Y_i - \\langle \\vec{X}_i , \\beta\\rangle\\). Therefore, the square \\(\\bigg(Y_i - \\langle \\vec{X}_i , \\beta\\rangle\\bigg)^2\\) is quadratic in \\(\\beta\\). Thus since the full expression \\(\\sum_{i=1}^N\\bigg(Y_i - \\langle \\vec{X}_i , \\beta\\rangle\\bigg)^2\\) is a sum of quadratic functions in \\(\\beta\\) it too is a quadratic function in \\(\\beta\\). Since all terms in the sum are squares, the full sum is never negative and its graph in \\(\\beta\\) is a non-hyperbolic paraboloid. Usually such shapes look like bowls. However, some can degenerate so that they become flat in one or more directions. Here’re some examples in R:\nNon-degenarte paraboloids look like this:\nnice.paraboloid = function(x,y)\r{\rreturn(x^2+0.5*y^2)\r}\rx = y = seq(from = -4, to = 4, by = 0.2)\rz = outer(x, y, nice.paraboloid)\rpersp(x, y, z,\rmain=\u0026quot;Plot of a Non-degenerate 2D Paraboloid\u0026quot;,\rtheta = 30, phi = 15,\rcol = \u0026quot;springgreen\u0026quot;, shade = 0.5)\rWe can see such a paraboloid is bowl shaped. More technically it’s strictly convex, with a clear unique minimum point. However, paraboloids can degenerate so that they flatten out in some directions:\ndegenerate.paraboloid = function(x,y)\r{\rreturn(x^2) #Does not change value as y changes\r}\rx = y = seq(from = -4, to = 4, by = 0.2)\rz = outer(x, y, degenerate.paraboloid)\rpersp(x, y, z,\rmain=\u0026quot;Plot of a Degenerate 2D Paraboloid\u0026quot;,\rtheta = 30, phi = 15,\rcol = \u0026quot;springgreen\u0026quot;, shade = 0.5)\rIn this example we changed the coefficient of \\(y\\) from 0.5 to 0. The result is that in the \\(y\\)-direction the paraboloid flattened out and it no longer looks bowl shaped. Instead there are infinitely many minimum points all on the axis \\(\\{(x,y): x = 0\\}\\). Note that if instead of making the coefficient of \\(y\\) equal to 0 we had made it a positive number very close to zero then the mimima would become unique but would become hard to distinguish from nearby points:\ntricky.paraboloid = function(x,y)\r{\rreturn(x^2+ 0.05*y^2) #Notice the coefficient of y is quite small\r}\rx = y = seq(from = -4, to = 4, by = 0.2)\rz = outer(x, y, tricky.paraboloid)\rpersp(x, y, z,\rmain=\u0026quot;Plot of a Nearly-Degenerate 2D Paraboloid\u0026quot;,\rtheta = 30, phi = 15,\rcol = \u0026quot;springgreen\u0026quot;, shade = 0.5)\rThese pictures show what can go wrong with the minima of quadratic functions like \\(SSE(\\beta)\\) and why regularization may be needed. Now to get back to the minimizing the sum of squares \\(SSE(\\beta) = \\sum_{i=1}^N\\bigg(Y_i - \\langle \\vec{X}_i , \\beta\\rangle\\bigg)^2\\). If you’re reading this article I’m going to assume you’ve seen this derivation before so I’ll move a bit fast.\nFirst we define \\(Y\\in \\mathbb{R}^{N\\times 1}\\) with \\(i\\)-th component equal to \\(Y_i\\). (Note an abuse of notation we are making: earlier \\(Y\\) denoted a real valued random variable, but now we are using the same symbol to denote the vector of the \\(N\\) realizations of this random variable.) In addition, let \\(X\\in \\mathbb{R}^{N\\times p}\\) with \\(i\\)-th row equal to \\(\\vec{X}_i\\). Then in matrix notation\n\\[\r\\sum_{i=1}^N\\bigg(Y_i - \\langle \\vec{X}_i , \\beta\\rangle\\bigg)^2 = (Y - X\\beta)^T(Y - X\\beta)\r\\]\rLet \\(\\hat{\\beta} = \\text{argmax}_{\\beta} \\ \\ (Y - X\\beta)^T(Y - X\\beta)\\) be the sought after minimizer. Since \\(\\hat{\\beta}\\) is a minizer in the interior of the domain of \\(SSE(\\beta)\\), the gradient of \\(SSE(\\beta)\\) at \\(\\hat{\\beta}\\) must be 0:\n\\[\r-2X^TY + 2X^TX\\hat{\\beta} = 0\r\\]\rtherefore we obtain the normal equations\n\\[\rX^TX\\hat{\\beta} = X^TY\r\\]\nThis is basically the same linear algebra problem as before: If the inverse \\((X^TX)^{-1}\\) existed and was numerically nice then we can solve for \\(\\hat{\\beta} = (X^TX)^{-1}X^TY\\). However, if this matrix inverse does not exist (as can happen when we do not have enough rows/samples for the given number of columns/unknowns) then this formula is not useful.\nBut as before we can simply regularize by replacing the matrix \\(X^TX\\) by \\(X^TX + \\lambda I\\) for some sufficiently large \\(\\lambda\\). Actually since \\(X^TX\\) is non-negative definite1 and symmetric all of it’s eigenvalues are non-negative. So any \\(\\lambda \u0026gt; 0\\) would be sufficient to shift the eigenvalues into positive numbers. Now the regularized problem becomes \\((X^TX + \\lambda I)\\hat{\\beta} = X^TY\\). Therefore we get the regularized MLE solution:\n\\[\r\\hat{\\beta}_{reg} := (X^TX + \\lambda I)^{-1}X^TY\r\\]\nDoes this regularized problem correspond to its own minimization problem? Yes! Working backwards, this new problem is equivalent to\n\\[\r-2X^TY + 2X^TX\\hat{\\beta} + 2\\lambda\\hat{\\beta}= 0\r\\]\rThe left had side is the gradient of \\((Y - X\\beta)^T(Y - X\\beta) + \\lambda\\sum_{j=1}^p\\beta_j^2 = (Y - X\\beta)^T(Y - X\\beta) + \\lambda \\langle \\beta, \\beta\\rangle\\) at \\(\\beta = \\hat{\\beta}\\) as can be checked. So the regularized problem corresponds to trying to minimize the expression \\((Y - X\\beta)^T(Y - X\\beta) + \\lambda\\sum_{j=1}^p\\beta_j^2 = (Y - X\\beta)^T(Y - X\\beta) + \\lambda \\langle \\beta, \\beta\\rangle\\). This of course is \\(L^2\\)-regularization. Thus we have derived \\(L^2\\)-regularization for OLS simply by seeking to transform the inverse problem that arises in OLS so that it may satisfy the Hadamard conditions.\n\r\rAn Illustrative Example\rBelow we can see geometrically what regularization does. The sum of squares expression \\((Y - X\\beta)^T(Y - X\\beta)\\) is quadratic in \\(\\beta\\), but may have a graph that is a degenerate paraboloid. This is what causes it to have multiple minimizers in OLS and what makes the matrix \\(X^TX\\) singular (more on this point in the next section). However the expression \\(\\lambda\\langle \\beta, \\beta\\rangle = \\lambda\\sum_{j = 1}^p\\beta_j^2\\) is a strictly positive-definite quadratic form. Its graph is a non-degenerate bowl shaped paraboloid.\nAdding a non-degenerate paraboloid to something that is not bowl shaped makes the second graph more bowl shaped! Moreover it shifts the minimum of the 2nd graph towards the mimimum of the bowl. As an illustration, let’s take a look at an example where this is easy to see.\nrm(list = ls())\rbumpy.function = function(x,y)\r{\rreturn(sin(x)+sin(y))\r}\rnice.paraboloid = function(x,y)\r{\rreturn(0.15*(x^2 + y^2)) #lambda = 0.15 is used\r}\rx = y = seq(from = -4, to = 4, by = 0.2)\rbumpy = outer(x, y, bumpy.function)\rparaboloid = outer(x, y, nice.paraboloid)\rbumpy.plus.paraboloid = bumpy + paraboloid\rpersp(x, y, bumpy,\rmain=\u0026quot;Graph of a bumpy function with multiple minima\u0026quot;,\rtheta = 30, phi = 15,\rcol = \u0026quot;springgreen\u0026quot;, shade = 0.5)\rpersp(x, y, paraboloid,\rmain=\u0026quot;Graph of a nice paraboloid\u0026quot;,\rtheta = 30, phi = 15,\rcol = \u0026quot;springgreen\u0026quot;, shade = 0.5)\rpersp(x, y, bumpy.plus.paraboloid,\rmain=\u0026quot;Graph of a regularized bumpy function = bumpy function + paraboloid\u0026quot;,\rtheta = 30, phi = 15,\rcol = \u0026quot;springgreen\u0026quot;, shade = 0.5)\rHere we see that the most important geometric aspect of the regularizing term \\(\\lambda\\langle\\beta, \\beta\\rangle\\) is the fact that it is strictly convex!! Although we will not dwell on it, it is impossible to overstate the theoretical importance of the previous sentence. As a matter of fact, geometrically speaking it’s clear that had we added any strictly convex function to the bumpy function we would have gotten something more bowl shaped. We will not go further into it here but you should know that convexity is one of those properties in mathematics out of which entire fields are created.\n\rThe Hessian matrix and more complex models\rIn the OLS problem above the Maximum Likelihood estimator turned out to be the one that minimized the sum of squares expression \\(SSE(\\beta) := (Y - X\\beta)^T(Y - X\\beta)\\). This expression can be expanded in matrix notation as\n\\[\rY^TY - Y^TX\\beta - \\beta^TX^TY + \\beta^TX^TX\\beta\r\\]\nWe see that there is a quadratic term (\\(\\beta^TX^TX\\beta\\)) and the rest are terms with powers of \\(\\beta\\) less than 2. The matrix of second derivatives of this expression (known as the Hessian matrix) is therefore just the matrix of coefficients of this quadratic term: \\(X^TX\\). This Hessian is exactly what was the star of the show in the OLS problem!\nThe Hessian of a function at a point tells us the convexity of the function at the point. If the Hessian is positive definite, then near the minimizing point the function is bowl shaped. If the Hessian is negative definite then near a maximizing point the function is shaped like an upside down bowl.\nMoreover, The Hessian is always a symmetric matrix by the equality of cross-derivatives. So the previous point is really a statement about Hessian’s eigenvalues. In short, if the Hessian has all positive eigenvalues then it is positive definite and the function is bowl shaped near its minimizer.\nThe OLS Hessian matrix \\(X^TX\\) is symmetric and non-negative definite, so the graph of the sum of squares \\(SSE(\\beta) := (Y - X\\beta)^T(Y - X\\beta)\\) can only fail to be bowl shaped near the minimizer \\(\\hat{\\beta}\\) if the matrix \\(X^TX\\) has eigenvalues that are equal 0 (or positive but close to 0 in the case numerical instability). In which case, the graph of \\(SSE(\\beta)\\) is a degenerate non-hyperbolic paraboloid and there are multiple minimizing solutions \\(\\beta\\).\nThus regularizing the matrix \\(X^TX\\) is just regularizing the Hessian matrix of the function \\(SSE(\\beta)\\) we want to minimize!! This fact is what allows us to take the idea beyond OLS.\nIndeed if \\(f(\\beta)\\) is any 2nd order differentiable cost function in any machine learning model then by the linearity of the derivative\n\\[\r\\text{Hessian}(f + \\lambda \\langle \\beta, \\beta\\rangle) = \\text{Hessian}(f) + \\lambda\\text{Hessian}(\\langle \\beta, \\beta\\rangle) = \\text{Hessian}(f) + \\lambda I\r\\]\nThere we used the fact that \\(\\text{Hessian}(\\langle \\beta, \\beta\\rangle) = \\text{Hessian}(\\sum_i^p \\beta_i^2) = I\\). Because \\(f\\) is almost arbitrary we see that we can apply \\(L^2\\)-regularization to a very large family of problems, with the goal being to regularize the Hessian of \\(f\\). As an example let’s look at some other kinds of regression problems. For OLS we assumed the conditional distribution \\(Y \\ \\ | \\ \\ \\vec{X} \\sim \\mathcal{N}(\\ \\langle \\vec{X} , \\beta\\rangle \\ ,\\ \\sigma^2)\\), but we may have chosen a different conditional distribution.\nIf \\(Y\\) takes on only values in the set \\(\\{0,1\\}\\) then it is a Bernoulli random variable. This is the case in logistic regression where the conditional distribution of \\(Y\\) given \\(\\vec{X}\\) is\r\\[\rY \\ \\ | \\ \\ \\vec{X} \\sim \\mathcal{B}(\\ p = \\phi(\\langle \\vec{X} , \\beta\\rangle) \\ )\r\\]\nwhere \\(\\mathcal{B(p)}\\) is a Bernoulli distribution with probability of a positive event equal to \\(p\\), \\(p = \\text{E}[Y|\\vec{X}] = \\phi(\\langle \\vec{X} , \\beta\\rangle)\\) is the probability of a positive event given \\(\\vec{X}\\), and \\(\\phi(t) = \\frac{e^t}{1+e^t}\\) is the standard logit. In this case the conditional density \\(p(Y|\\vec{X})\\) can be written as\n\\[\rp(Y|\\vec{X}) = p^Y\\big(1 - p)\\big)^{1-Y} =\\phi(\\langle \\vec{X} , \\beta\\rangle)^Y\\big(1 - \\phi(\\langle \\vec{X} , \\beta\\rangle)\\big)^{1-Y}\r\\]\rSo the negative log-likelihood is given by\n\\[\r-\\mathcal{l}(\\beta) = -\\sum_{i=1}^N Y_i\\log(\\phi(\\langle \\vec{X}_i , \\beta\\rangle)) + (1-Y_i)\\log(1-\\phi(\\langle \\vec{X}_i , \\beta\\rangle))\r\\]\nThis function may or may not look bowl shaped (i.e. strictly convex) near the \\(\\hat{\\beta}\\) that minimizes it. In case it doesn’t we can make it so by adding \\(\\lambda \\langle \\beta, \\beta\\rangle = \\lambda\\sum_{j = 1}^p\\beta_j^2\\) for some sufficiently large \\(\\lambda\\) and minimizing this new problem. The same applies to generalized linear models, neural networks, etc.\n\r\rBias-Variance trade offs and Regularization\rAbove we used regularization methods to make a problem “nicer” in the numerical sense (i.e. satisfying Hadamard’s conditions). But what does “nicer” mean in the statistical context? That is a multifaceted question. The first step is to recognize that what might be viewed as instability from the numerical point of view, can be understood as high variance from the statistical point of view.\nWe illustrate with the OLS estimator. Suppose that the matrix \\(X^TX\\) is indeed invertible. The standard OLS estimator is the random vector given by the normal equations:\n\\[\r\\hat{\\beta} = (X^TX)^{-1}X^TY\r\\]\nWe see that this is an unbiased estimator of \\(\\beta\\):\n\\[\r\\text{E}[\\hat{\\beta}] = \\text{E}\\big[\\text{E}[\\hat{\\beta}|X]\\big] = \\text{E}\\bigg[(X^TX)^{-1}X^T\\text{E}[Y|X]\\bigg] = \\text{E}\\bigg[(X^TX)^{-1}X^TX\\beta\\bigg] = \\text{E}[\\beta] = \\beta\r\\]\nMoreover, it’s easy enough to compute the conditional covariance matrix of \\(\\hat{\\beta}\\):\r\\[\r\\text{Var}[\\hat{\\beta}|X] = (X^TX)^{-1}X^T\\cdot \\text{Var}[Y|X] \\cdot X(X^TX)^{-1} = (X^TX)^{-1}X^T\\cdot \\sigma^2 I \\cdot X(X^TX)^{-1} \\]\n\\[\r= \\sigma^2 (X^TX)^{-1}\r\\]\nThe unconditional covariance matrix can be computed as\n\\[\r\\text{Var}[\\hat{\\beta}] = \\text{E}[\\text{Var}[\\hat{\\beta}|X]] + \\text{Var}[\\text{E}[\\hat{\\beta}|X]] \\]\n\\[\r= \\sigma^2\\text{E}[(X^TX)^{-1}] + \\text{Var}[\\beta] = \\sigma^2\\text{E}[(X^TX)^{-1}]\r\\]\nThis is harder to compute because it depends on the distribution of the random matrix \\(X\\). Regardless, we can see that what controls the variance of the estimator \\(\\hat{\\beta}\\) (whether conditional or not) is the inverse matrix \\((X^TX)^{-1}\\). This is interesting because it shows that the matrix we identified as the Hessian of the OLS cost function (\\(X^TX\\)) is also the matrix that controls the covariance of the OLS estimator.2\nIf any of the eigenvalues of the matrix \\(X^TX\\) were “close” to \\(0\\) then the eigenvalues of the inverse will be very large, causing the variance of \\(\\hat{\\beta}\\) to be very large. If you’re familiar with VIFs, this is what causes large variance inflation factors.\nRegularization is used to reduce the variance in this estimator. If we denote the regularized estimator by:\r\\[\r\\hat{\\beta}_{reg} = (X^TX + \\lambda I)^{-1}X^TY\r\\]\rThen this estimator is biased away from \\(\\beta\\). To see this we first compute the conditional mean:\n\\[\r\\text{E}[\\hat{\\beta}_{reg}|X] = (X^TX + \\lambda I)^{-1}X^TX\\beta\r\\]\n\\[\r= (X^TX + \\lambda I)^{-1}(X^TX + \\lambda I)\\beta - \\lambda (X^TX + \\lambda I)^{-1}\\beta\r\\]\n\\[\r= \\beta - \\lambda (X^TX + \\lambda I)^{-1}\\beta\r\\]\nHence\r\\[\r\\text{E}[\\hat{\\beta}_{reg}] = \\beta - \\lambda\\text{E}\\big[(X^TX + \\lambda I)^{-1}\\big]\\beta\r\\]\rwhich is “\\(\\beta\\) minus something” and hence not equal to \\(\\beta\\). However the effect on the variance is better:\n\\[\r\\text{Var}[\\hat{\\beta}_{reg}|X] = (X^TX + \\lambda I)^{-1}X^T\\cdot\\text{Var}[Y|X]\\cdot X(X^TX + \\lambda I)^{-1}\r\\]\n\\[\r= \\sigma^2(X^TX + \\lambda I)^{-1}X^TX(X^TX + \\lambda I)^{-1}\r\\]\n\\[\r= \\sigma^2(X^TX + \\lambda I)^{-1}(X^TX+\\lambda I)(X^TX + \\lambda I)^{-1} - \\sigma^2\\lambda(X^TX + \\lambda I)^{-2}\r\\]\n\\[\r= \\sigma^2(X^TX + \\lambda I)^{-1} - \\sigma^2\\lambda(X^TX + \\lambda I)^{-2}\r\\]\rThis variance formula may look messy but the gist is that instead of inverting \\(X^TX\\) we are inverting \\(X^TX + \\lambda I\\). The matrix \\(X^TX + \\lambda I\\) has larger eigenvalues than the matrix \\(X^TX\\). Therefore \\(\\text{Var}[\\hat{\\beta}_{reg}|X] = \\sigma^2(X^TX + \\lambda I)^{-1} - \\sigma^2\\lambda(X^TX + \\lambda I)^{-2}\\) is smaller than \\(\\text{Var}[\\hat{\\beta}|X] = \\sigma^2 (X^TX)^{-1}\\) in the sense that it has smaller eigenvalues. Thus regularization has increased bias, but reduced variance. Similar effects hold for more complex models than OLS, but instead of chasing formulas the read should try cooking up some numerical examples via Monte Carlo.\n\rWhat about the Bayesian view point?\rA very natural perspective on regularization can be found in Bayesian modeling, where regularization terms amount to simply specifying prior distributions. However, this is standard Bayesian theory and this post is already long enough :P\n\r\rIndeed suppose \\(v\\in \\mathbb{R}^p\\) is any vector. Then \\(\\langle v, X^TXv\\rangle = \\langle Xv,Xv\\rangle = ||Xv||^2 \\ge 0\\). Hence \\(X^TX\\) is always non-negative definite.↩︎\n\rThis is a general feature of Maximum Likelihood estimators called “asymptotic efficiency”, where the covariance matrix of the MLE estimator approaches a “best possible” covariance matrix as the sample size increases. Essentially the best possible covariance matrix that an unbiased estimator of \\(\\beta\\) can have is given given by the Cramer-Rao Bound and is determined by the inverse of the Fisher Information matrix, whose \\(ij\\)-component is \\(-\\text{E}[\\partial^2\\log(p(Y, \\vec{X}| \\beta))/\\partial \\beta_i\\partial \\beta_j]\\). The beauty is that the Hessian of the negative loglikelihood is the sample estimator of this Fisher Information (where expectation is replaced by average over samples). This is why the Hessian is showing up as the determining factor in estimator covariance.↩︎\n\r\r\r","date":1593648000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593648000,"objectID":"d744f1e457e96ffcd58858c693c87638","permalink":"/post/004_regularization/main/","publishdate":"2020-07-02T00:00:00Z","relpermalink":"/post/004_regularization/main/","section":"post","summary":"Introduction\rMany newcomers to machine learning know about regularization, but they may not understand it yet. In particular, they may not know why regularization has that name. In this post we discuss the numerical and statistical significance of regularization methods in machine learning and more general statistical models.","tags":["r","regularization","regular","singular","Hessian","machine learning","statistical learning","bias variance tradeoff"],"title":"In Machine Learning, why is Regularization called Regularization?","type":"post"},{"authors":null,"categories":["Theory"],"content":"\rIntroduction\rThis is the first in a series of posts on Expectation Maximization (EM) type algorithms. Our goal will be to motivate some of the theory behind these algorithms. In later posts we will implement examples in C++, often with the help of the Eigen linear algebra library.\n\rMaximum likelihood\rA large subset of statistics is concerned with determining properties of a distribution by using data that is assumed to be generated by that distribution. A common example is Maximum Likelihood Estimation (MLE). Here one assumes that a vector of observed data \\(\\vec{x}\\in\\mathbb{R}^N\\) is the realization of a random vector \\(\\vec{X}\\) with a probability density \\(p(\\vec{X} \\ | \\ \\theta)\\) that depends on a vector of parameters \\(\\theta\\). MLE amounts to estimating \\(\\theta\\) with the value that makes this probability density has high as possible for the observed data:\n\\[\r\\hat{\\theta} := \\text{argmax}_{\\theta} \\ \\ p(\\vec{x} \\ | \\ \\theta)\r\\]\rAs a function of \\(\\theta\\), the density \\(\\mathcal{L}(\\theta; \\vec{x}) := p(\\vec{x} \\ | \\ \\theta)\\) is called the likelihood. Because probability densities are positive for the realized values \\(\\vec{x}\\) of \\(\\vec{X}\\), the above problem is equivalent to maximizing the logarithm of the likelihood:\r\\[\r\\hat{\\theta} := \\text{argmax}_{\\theta} \\ \\ \\log(p(\\vec{x} \\ | \\ \\theta))\r\\]\r(The main practical reason behind this log transformation is that it often makes the problem easier numerically. The theoretical advantage is that it ties MLE to the theory of the Fisher Information).\n\rDependence structures and problems with hidden variables\rThe situation in the last section can be summarized by the simple dependence structure (or Markov diagram) \\(\\theta \\to \\vec{X}\\). That is, given the value of \\(\\theta\\) we can determined the distribution of \\(\\vec{X}\\), namely \\(p(\\vec{X} \\ | \\ \\theta)\\).\nHowever, in many applications we may only have partial observations of the data we want, with some of the relevant information remaining unobserved/hidden. For example, suppose 100 identical and independent dice are thrown in an experiment. The dice are not necessarily uniformly weighted, with probabilities of landing 1,2,…,6 given by \\(\\theta = [p_1, p_2,...,p_6]\\). Suppose the dice land with values represented by \\(\\vec{X} = [X_1, X_2, ... X_{100}]\\) with \\(X_i\\) being the number the \\(i^{th}\\) die lands on. Suppose also that in the experiment we are only able to observe whether each die landed on an even or odd number. That is, we observe a vector \\(\\vec{Y}\\) given by\n\\[\rY_i = X_i \\mod 2\r\\]\nfor \\(i \\in \\{1, 2, ... 100\\}\\). In this case the dependence structure is a little more complex: \\(\\theta \\to \\vec{X} \\to \\vec{Y}\\). That is, once we know the value of \\(\\vec{X}\\) we can fully specify the distribution of \\(\\vec{Y}\\) without knowing the value of \\(\\theta\\). We would have the Markov property for densities:\n\\[\rp(\\vec{y} \\ | \\ \\vec{x}, \\theta) = p(\\vec{y} \\ | \\ \\vec{x})\r\\]\nIn general, we have a dependence structure given by \\(\\theta \\to \\vec{X} \\to \\vec{Y}\\), we observe only \\(\\vec{Y}=\\vec{y}\\) and we want to estimate the parameters \\(\\theta\\). The MLE estimator would be:\r\\[\r\\hat{\\theta} := \\text{argmax}_{\\theta} \\ \\ \\log(p(\\vec{y} \\ | \\ \\theta))\r\\]\rAll of the theory of MLE applies in this case. In the example above this would be relatively easy. However, there are times this maximization problem is very difficult. Often the density \\(p(\\vec{y} \\ | \\ \\theta)\\) may be much more complicated than the density \\(p(\\vec{x} \\ | \\ \\theta)\\) of the hidden data that we wish we had.\nIn such as situation, if we knew \\(\\vec{x}\\) then we can replace the above problem with \\(\\hat{\\theta} := \\text{argmax}_{\\theta} \\ \\ \\log(p(\\vec{x} \\ | \\ \\theta))\\). In fact, we wouldn’t even need to know exactly what the value of \\(\\vec{x}\\) is but only what the value of \\(\\log(p(\\vec{x} \\ | \\ \\theta))\\) is for a given \\(\\theta\\).\n\rA general recipe for EM algorithms\rThe idea of EM is indeed to try and maximize \\(\\log(p(\\vec{x} \\ | \\ \\theta))\\) instead of \\(\\log(p(\\vec{y} \\ | \\ \\theta))\\), but because we do not know \\(\\log(p(\\vec{x} \\ | \\ \\theta))\\) to instead use an approximation/estimate of it.\nHow to approximate such an expression? The quantity \\(\\log(p(\\vec{x} \\ | \\ \\theta))\\) is a random variable (depending on the unknown value \\(\\vec{x}\\) of \\(\\vec{X}\\)). To estimate it in a meaningful way we need to use the most informative distribution related to \\(\\vec{x}\\). Because we know \\(\\vec{y}\\) the best such distribution is \\(p(\\vec{x}|\\vec{y},\\theta)\\).\nThe problem is this distribution (or any other) will necessarily depend \\(\\theta\\), which we do not know! At first this seems like a circular trap, because to estimate \\(\\log(p(\\vec{x} \\ | \\ \\theta))\\) using \\(p(\\vec{x}|\\vec{y},\\theta)\\) we need to know \\(\\theta\\), but to estimate \\(\\theta\\) we need to know \\(\\log(p(\\vec{x} \\ | \\ \\theta))\\). However the trap hints at a solution: simply alternate between estimating the random variable \\(\\log(p(\\vec{x} \\ | \\ \\theta))\\) using a current guess of \\(\\theta\\) and then use this updated estimate of \\(\\log(p(\\vec{x} \\ | \\ \\theta))\\) to update our guess of \\(\\theta\\). More formally we can summarize EM in 5 steps:\n\rStep 1: Let \\(m = 0\\). Make an initial estimate \\(\\theta_m\\) for \\(\\theta\\).\n\rStep 2: Given the observed data \\(\\vec{y}\\) and pretending for the moment that our current guess \\(\\theta_m\\) is correct, construct the conditional probability distribution \\(p(\\vec{x}|\\vec{y},\\theta_m)\\) of the hidden data \\(\\vec{x}\\) given all known information.\n\rStep 3: Using the distribution \\(p(\\vec{x}|\\vec{y},\\theta_m)\\) construct an estimator/approximation of the desired log-likelihood \\(\\log(p(\\vec{x} \\ | \\ \\theta))\\) for arbitrary \\(\\theta\\). We denote this approximation by \\(Q(\\theta|\\theta_m)\\).\n\rStep 4: Set \\(\\theta_{m+1}\\) equal to a value of \\(\\theta\\) that maximizes the current approximation \\(Q(\\theta|\\theta_m)\\) of \\(\\log(p(\\vec{x} \\ | \\ \\theta))\\).\n\rStep 5: Return to step 2 and repeat until some stopping criteria is met.1\n\r\rPractically speaking, this algorithm would be applied when each of these steps is significantly easier than the original MLE problem of \\(\\hat{\\theta} := \\text{argmax}_{\\theta} \\ \\ \\log(p(\\vec{y} \\ | \\ \\theta))\\). As a general example, this is often the case when the model is linear with respect to \\(\\vec{X}\\), but the information loss of going from \\(\\vec{X}\\) to \\(\\vec{Y}\\) is nonlinear and non-invertible (we’ll give examples in later posts).\n\rConstructing an estimator for \\(\\log(p(\\vec{X} \\ | \\ \\theta))\\)\rHow do we fill in the blank left by step 3 above? That is, how do we use the probability density \\(p(\\vec{x}|\\vec{y},\\theta_m)\\) to estimate the value of the random variable \\(\\log(p(\\vec{X} \\ | \\ \\theta))\\)? Two possibilities come to mind.\nPoint-estimate type EM\rOne possibility is to let\r\\[\r\\vec{x}_m = \\vec{x}_m(\\vec{y}, \\theta_m) := \\text{argmax}_{\\vec{x}} \\ p(\\vec{x}|\\vec{y},\\theta_m)\r\\]\rand then define\r\\[\rQ(\\theta | \\theta_m) := \\log(p(\\vec{x}_m \\ | \\ \\theta))\r\\]\rThis is called point-estimate EM. Here we use “the most likely” value of \\(\\vec{X}\\) as determined by the density \\(p(\\vec{x}|\\vec{y},\\theta_m)\\) and then impute this value into our log-likelihood that we want to maximize. Another possibility would be to let\n\\[\r\\vec{x}_m = \\vec{x}_m(\\vec{y}, \\theta_m) := \\ \\text{E}_{\\vec{X} \\ | \\ \\vec{Y} \\ = \\ \\vec{y}, \\ \\theta_m} \\big[ \\vec{X}\\big]\r\\]\rand let \\(Q\\) be as before.\nThe idea of these type of EM algorithms is to first estimate the missing data \\(\\vec{x}\\) and then impute the result into \\(log(p(\\vec{x}\\ |\\ \\theta))\\).\n\rExpectation EM (i.e. standard EM)\rThere is a theoretically more elegant way. As mentioned earlier, we do not in fact need an estimate of the missing data \\(\\vec{x}\\). One of the best ways to estimate the value of a random variable with respect to a conditional distribution is to simply compute the conditional expectation of that variable with respect to that conditional distribution:\n\\[\rQ(\\theta | \\theta_m) \\ := \\ \\text{E}_{\\vec{X} \\ | \\ \\vec{Y} \\ = \\ \\vec{y}, \\ \\theta_m} \\big[ \\log(p(\\vec{X} \\ | \\ \\theta)) \\big] = \\int_{\\mathcal{X}} \\log(p(\\vec{x} \\ | \\ \\theta)) \\ p(\\vec{x}|\\vec{y},\\theta_m) \\ d\\vec{x} \\]\rHere we’re computing the mean of \\(\\log(p(\\vec{X} \\ | \\ \\theta))\\) with respect to the density \\(p(\\vec{x}|\\vec{y},\\theta_m)\\). As is common when using expectations, this second method has some advantages we’ll see later. When we refer to EM we will always mean this case, unless otherwise specified.\n\r\r\\(Q(\\theta|\\theta_m)\\) for I.I.D. samples\rSo far everything has been rather general, applying to any random vectors \\(\\vec{X}\\) and \\(\\vec{Y}\\). Many problems assume that data are generated independently and identically distributed (I.I.D.) so it’s helpful to have a formulation for this particular case.\nProposition: Suppose that the components of \\(\\vec{X}\\) are IID (given \\(\\theta\\)), that is:\r\\[\rp(\\vec{x}|\\theta) = \\prod_{i = 1}^N p(x_i|\\theta) \\ \\qquad \\forall x, \\theta\r\\]\rSuppose also that the dependence structure \\(\\theta \\to \\vec{X} \\to \\vec{Y}\\) splits into subgraphs as \\(\\theta \\to X_i \\to Y_i\\) for all \\(i = 1, 2, ..., N\\). This just means that given \\(X_i\\), the distribution \\(Y_i\\) is independent of all other variables:\r\\[\rp(y_i|\\vec{x}, \\theta, y_1, y_2, ..., y_{i-1}, y_{i+1}, ..., y_N) = p(y_i|x_i)\r\\]\rThen \\(Q(\\theta|\\theta_m):= \\ \\text{E}_{\\vec{X} \\ | \\ \\vec{Y} \\ = \\ \\vec{y}, \\ \\theta_m} \\big[ \\log(p(\\vec{X} \\ | \\ \\theta)) \\big]\\) can be written as:\r\\[\rQ(\\theta|\\theta_m) = \\sum_{i=1}^N Q_i(\\theta|\\theta_m)\r\\]\rwhere\r\\[\rQ_i(\\theta|\\theta_m) := \\ \\text{E}_{X_i \\ | \\ Y_i \\ = \\ y_i, \\ \\theta_m} \\big[ \\log(p(X_i \\ | \\ \\theta)) \\big].\r\\]\rProof: The proof begins by showing that the joint elements \\((X_i,Y_i)\\) are independent across \\(i\\), that is:\r\\[\rp(\\vec{x},\\vec{y}|\\theta) = \\prod_{i = 1}^N p(x_i, y_i|\\theta). \\]\rTo prove this we start by applying the multiplication theorem for probability densities:\r\\[\\begin{equation}\r\\begin{aligned}\rp(\\vec{x},\\vec{y}|\\theta) \u0026amp;= p(y_1|y_2,y_3, ..., y_N, \\vec{x},\\theta)...p(y_N|\\vec{x},\\theta)p(\\vec{x}|\\theta) \\qquad \\text{by the multiplication theorem}\\\\\r\u0026amp;= p(y_1|x_1,\\theta)...p(y_N|x_N,\\theta)p(\\vec{x}|\\theta) \\qquad \\text{by conditional independence but keeping theta} \\\\\r\u0026amp;= p(\\vec{x}|\\theta)\\prod_{i=1}^Np(y_i|x_i,\\theta) \\\\\r\u0026amp;=\\prod_{i=1}^Np(y_i|x_i,\\theta)p(x_i|\\theta) \\qquad \\text{by independence of the x\u0026#39;s} \\\\\r\u0026amp;= \\prod_{i=1}^Np(y_i,x_i|\\theta).\r\\end{aligned}\r\\end{equation}\\]\nNext we have that for each \\(i\\)\n\\[\\begin{equation}\r\\begin{aligned}\rp(x_i|\\vec{y},\\theta) \u0026amp;= \\frac{p(x_i,\\vec{y}|\\theta)}{p(\\vec{y}|\\theta)} \\qquad \\text{by Bayes} \\\\\r\u0026amp;= \\frac{\\int p(\\vec{x},\\vec{y}|\\theta)dx_1...dx_{i-1}dx_{i+1}...dx_n}{\\int p(\\vec{x},\\vec{y}|\\theta)d\\vec{x}} \\\\\r\u0026amp;= \\frac{\\int \\prod_{j=1}^Np(y_j,x_j|\\theta)dx_1...dx_{i-1}dx_{i+1}...dx_n}{\\int \\prod_{j=1}^Np(y_j,x_j|\\theta)d\\vec{x}} \\\\\r\u0026amp;= \\frac{p(x_i,y_i|\\theta) \\prod_{j=1, j \\ne i}^N \\int p(y_j,x_j|\\theta)dx_j}{\\prod_{j=1}^N\\int p(y_j,x_j|\\theta) dx_j} \\\\\r\u0026amp;= \\frac{p(x_i,y_i|\\theta) \\prod_{j=1, j \\ne i}^N p(y_j|\\theta)}{\\prod_{j=1}^N p(y_j|\\theta)}\\\\\r\u0026amp;= \\frac{p(x_i,y_i|\\theta)}{p(y_i|\\theta)}\\\\\r\u0026amp;= p(x_i|y_i,\\theta)\r\\end{aligned}\r\\end{equation}\\]\nHence \\(p(x_i|\\vec{y},\\theta) = p(x_i|y_i,\\theta)\\). Therefore we have\n\\[\\begin{equation}\r\\begin{aligned}\rQ(\\theta, \\theta_m) \u0026amp;= \\text{E}_{\\vec{X} \\ | \\ \\vec{Y} \\ = \\ \\vec{y}, \\ \\theta_m} \\big[ \\log(p(\\vec{X} \\ | \\ \\theta)) \\big] \\\\\r\u0026amp;= \\text{E}_{\\vec{X} \\ | \\ \\vec{Y} \\ = \\ \\vec{y}, \\ \\theta_m} \\big[ \\log(\\prod_{i = 1}^N p(X_i \\ | \\ \\theta)) \\big] \\\\\r\u0026amp;= \\text{E}_{\\vec{X} \\ | \\ \\vec{Y} \\ = \\ \\vec{y}, \\ \\theta_m} \\big[ \\sum_{i = 1}^N \\log(p(X_i \\ | \\ \\theta)) \\big]\\\\\r\u0026amp;= \\sum_{i = 1}^N \\text{E}_{X_i \\ | \\ \\vec{Y} \\ = \\ \\vec{y}, \\ \\theta_m} \\big[ \\log(p(X_i \\ | \\ \\theta)) \\big] \\\\\r\u0026amp;= \\sum_{i = 1}^N \\text{E}_{X_i \\ | \\ Y_i \\ = \\ y_i, \\ \\theta_m} \\big[ \\log(p(X_i \\ | \\ \\theta)) \\big]\r= \\sum_{i=1}^N Q_i(\\theta|\\theta_m)\r\\end{aligned}\r\\end{equation}\\]\rWhere we used \\(p(x_i|\\vec{y},\\theta) = p(x_i|y_i,\\theta)\\) in the 2nd to last equality. QED\n\rMaximum A Posteriori EM and regularizing priors\rThe EM algorithm is easily extendable to regularized MLE. This is usually referred to as Maximum A Posteriori (MAP) in the Bayesian setting, which we adopt. Here the penalty term is interpreted as the log of the prior density on \\(\\theta\\), and the function to be maximized is the posterior density of \\(\\theta\\) given the data. By Bayes’ Theorem\r\\[\rp(\\theta|\\vec{y}) \\propto p(\\vec{y}|\\theta)p(\\theta)\r\\]\rwhere the proportionality constant is independent of \\(\\theta\\). Thus the MAP estimator is\r\\[\r\\hat{\\theta}_{MAP} := \\text{argmax}_{\\theta} \\ \\log(p(\\theta|\\vec{y})) \\ = \\text{argmax}_{\\theta} \\ \\log(p(\\vec{y}|\\theta)) + \\log(p(\\theta))\r\\]\rThe way to extend EM to this situation is clear (at least formally): Simply replace the maximization step (step 4 above) in EM with maximizing \\(Q(\\theta|\\theta_m) + \\log(p(\\theta))\\) instead of simply \\(Q(\\theta|\\theta_m)\\):\n\\[\r\\theta_{m+1} := \\text{argmax}_{\\theta} \\ \\ \\ Q(\\theta|\\theta_m) + \\log(p(\\theta))\r\\]\rwhere as before \\(Q\\) is given by\n\\[\rQ(\\theta | \\theta_m) \\ := \\ \\text{E}_{\\vec{X} \\ | \\ \\vec{Y} \\ = \\ \\vec{y}, \\ \\theta_m} \\big[ \\log(p(\\vec{X} \\ | \\ \\theta)) \\big] = \\int_{\\mathcal{X}} \\log(p(\\vec{x} \\ | \\ \\theta)) \\ p(\\vec{x}|\\vec{y},\\theta_m) \\ d\\vec{x} \\]\n\rMonotonicity of the EM algorithm\rAt this point the reader has all the theory needed to begin applying EM where they believe it’s a good fit. Before we end the post though let’s mention at least one result that shows that EM is indeed a generalization of MLE to the case of hidden data: under relatively weak assumptions of the algorithm causes the log-likelihood \\(\\log(p(\\vec{y}|\\theta_m))\\) to be an increasing sequence in \\(m\\).\n\r\rStep 2 allows for a whole family of such algorithms, one for each possible approximator to \\(\\log(p(\\vec{x} \\ | \\ \\theta))\\). Step 4 can also be generalized. Since the value of \\(\\theta_{m+1}\\) maximizes \\(Q(\\theta | \\theta_m)\\) then \\(Q(\\theta_{m+1} | \\theta_m) \\ge Q(\\theta_m | \\theta_m)\\). Instead of seeking to maximize \\(Q(\\theta | \\theta_m)\\) we may simply seek a value of \\(\\theta_{m+1}\\) that improves on \\(\\theta_m\\) in the sense of this inequality. For step 5, the stopping criteria are up to the implementer.↩︎\n\r\r\r","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"e7e53ed51a7b3183f7b996ca1cb24d4e","permalink":"/post/003_em1/main/","publishdate":"2020-07-01T00:00:00Z","relpermalink":"/post/003_em1/main/","section":"post","summary":"Introduction\rThis is the first in a series of posts on Expectation Maximization (EM) type algorithms. Our goal will be to motivate some of the theory behind these algorithms. In later posts we will implement examples in C++, often with the help of the Eigen linear algebra library.","tags":["expectation maximization","em algorithm","em"],"title":"Expectation Maximization, Part 1: Motivation and Recipe","type":"post"},{"authors":null,"categories":["C++","R"],"content":"\rIntroduction\rIn this post we give a simple illustrative example of how data generated by R code can be used by compiled languages such as C++ at compile time, instead of run-time, inside Rmarkdown.\nThis is an example of inter-language code generation. Metaprogramming/code generation is an extremely powerful technique but it’s also one that is very easy to overdo. This is just a fun example to learn from. Thorough testing is very important for any production code.\n\rUsing other languages in Rmarkdown\rOut of the box Rmarkdown can work with the following languages assuming a proper back-end is available:\nnames(knitr::knit_engines$get())\r## [1] \u0026quot;awk\u0026quot; \u0026quot;bash\u0026quot; \u0026quot;coffee\u0026quot; \u0026quot;gawk\u0026quot; \u0026quot;groovy\u0026quot; ## [6] \u0026quot;haskell\u0026quot; \u0026quot;lein\u0026quot; \u0026quot;mysql\u0026quot; \u0026quot;node\u0026quot; \u0026quot;octave\u0026quot; ## [11] \u0026quot;perl\u0026quot; \u0026quot;psql\u0026quot; \u0026quot;Rscript\u0026quot; \u0026quot;ruby\u0026quot; \u0026quot;sas\u0026quot; ## [16] \u0026quot;scala\u0026quot; \u0026quot;sed\u0026quot; \u0026quot;sh\u0026quot; \u0026quot;stata\u0026quot; \u0026quot;zsh\u0026quot; ## [21] \u0026quot;highlight\u0026quot; \u0026quot;Rcpp\u0026quot; \u0026quot;tikz\u0026quot; \u0026quot;dot\u0026quot; \u0026quot;c\u0026quot; ## [26] \u0026quot;fortran\u0026quot; \u0026quot;fortran95\u0026quot; \u0026quot;asy\u0026quot; \u0026quot;cat\u0026quot; \u0026quot;asis\u0026quot; ## [31] \u0026quot;stan\u0026quot; \u0026quot;block\u0026quot; \u0026quot;block2\u0026quot; \u0026quot;js\u0026quot; \u0026quot;css\u0026quot; ## [36] \u0026quot;sql\u0026quot; \u0026quot;go\u0026quot; \u0026quot;python\u0026quot; \u0026quot;julia\u0026quot; \u0026quot;sass\u0026quot; ## [41] \u0026quot;scss\u0026quot; \u0026quot;theorem\u0026quot; \u0026quot;lemma\u0026quot; \u0026quot;corollary\u0026quot; \u0026quot;proposition\u0026quot;\r## [46] \u0026quot;conjecture\u0026quot; \u0026quot;definition\u0026quot; \u0026quot;example\u0026quot; \u0026quot;exercise\u0026quot; \u0026quot;proof\u0026quot; ## [51] \u0026quot;remark\u0026quot; \u0026quot;solution\u0026quot;\rAlthough we can use R’s native foreign function interface to call compiled code, for C++ a higher level alternative is to use Rcpp. In Rmarkdown we can compile C++ code chunks using Rcpp and export the compiled functions to be available for use in R.\nAs a common example, we can compile the following code\n#include \u0026lt;Rcpp.h\u0026gt;\rusing namespace Rcpp;\r// [[Rcpp::export]]\rNumericVector timesTwo(NumericVector x) {\rreturn x * 2;\r}\rand use the exported function in R\ntimesTwo(1:10)\r## [1] 2 4 6 8 10 12 14 16 18 20\r\rRegistering a user-defined language engine in Knitr\rWe can create user-defined engines to control exactly how the code chunk is sourced, or even modify existing engines. To get an idea we can look at the default Rcpp engine used by knitr:\nknitr::knit_engines$get()$Rcpp\r## function (options) ## {\r## sourceCpp = getFromNamespace(\u0026quot;sourceCpp\u0026quot;, \u0026quot;Rcpp\u0026quot;)\r## code = one_string(options$code)\r## opts = options$engine.opts\r## cache = options$cache \u0026amp;\u0026amp; (\u0026quot;cacheDir\u0026quot; %in% names(formals(sourceCpp)))\r## if (cache) {\r## opts$cacheDir = paste(valid_path(options$cache.path, ## options$label), \u0026quot;sourceCpp\u0026quot;, sep = \u0026quot;_\u0026quot;)\r## opts$cleanupCacheDir = TRUE\r## }\r## if (!is.environment(opts$env)) ## opts$env = knit_global()\r## if (options$eval) {\r## message(\u0026quot;Building shared library for Rcpp code chunk...\u0026quot;)\r## do.call(sourceCpp, c(list(code = code), opts))\r## }\r## options$engine = \u0026quot;cpp\u0026quot;\r## engine_output(options, code, \u0026quot;\u0026quot;)\r## }\r## \u0026lt;environment: namespace:knitr\u0026gt;\rUsing the default engine above as a template we can define a new knitr engine for compiling C++. One that can read and make use of more dynamic R data in C++ before compilation (or even dynamically create Makevars files to control compilation flags). First let’s include the knitr package:\nlibrary(knitr)\rNext let’s take a crack at defining a new engine to compile C++ code. In this example we will modify the current Rcpp engine to take in an extra field (but otherwise behave the same).\nknit_engines$set(RcppFoo = function(options) {\rextra = options$extra\rsourceCpp = getFromNamespace(\u0026quot;sourceCpp\u0026quot;, \u0026quot;Rcpp\u0026quot;)\r## Code is read as a list of strings, one list element per line\r## Here we append extra code that may be defined in R to the ## code written in the chunk\rcode = c(extra, options$code)\rcode = paste(code, collapse = \u0026#39;\\n\u0026#39;)\ropts = options$engine.opts\rif (!is.environment(opts$env)) opts$env = knit_global()\rif (options$eval) { message(\u0026quot;Building shared library for Rcpp code chunk...\u0026quot;)\rdo.call(sourceCpp, c(list(code = code), opts))\r}\roptions$engine = \u0026quot;cpp\u0026quot;\rengine_output(options, options$code, paste(\u0026quot;Added the lines:\\n\u0026quot;, paste(extra, collapse = \u0026#39;\\n\u0026#39;), sep = \u0026#39;\\n\u0026#39;))\r})\rNext we test by creating some data in R and using that as a compile time constant in C++. Here we pass values of pi and e as static const doubles to C++ (a much cleaner API is possible of course).\nconstants = list(\rpaste(\u0026#39;static const double Pi =\u0026#39;, pi, \u0026#39;;\u0026#39;),\rpaste(\u0026#39;static const double Euler =\u0026#39;, exp(1),\u0026#39;;\u0026#39;)\r)\rThis already highlights a danger as we have not considered exactly how R might convert these double precision floating point numbers to strings. Regardless, we proceed. To use the new engine we run the engine as {RcppFoo test_chunk, extra = constants}\n#include \u0026lt;Rcpp.h\u0026gt;\rusing namespace Rcpp;\r// [[Rcpp::export]]\rNumericVector timesFoo(NumericVector x) {\rreturn x * Pi + Euler;\r}\r## Added the lines:\r## ## static const double Pi = 3.14159265358979 ;\r## static const double Euler = 2.71828182845905 ;\rx = timesFoo(1:10)\rprint(x)\r## [1] 5.859874 9.001467 12.143060 15.284652 18.426245 21.567838 24.709430\r## [8] 27.851023 30.992616 34.134208\rWe get almost the same result as in R\ny = pi*(1:10)+exp(1)\rprint(y)\r## [1] 5.859874 9.001467 12.143060 15.284652 18.426245 21.567838 24.709430\r## [8] 27.851023 30.992616 34.134208\rBut metaprogramming can be dangerous when mixed with floating point arithmetic. In this case some loss of precision occurred with the doubles when converting to strings:\nx - y\r## [1] 1.776357e-15 0.000000e+00 -3.552714e-15 -7.105427e-15 -1.065814e-14\r## [6] -1.421085e-14 -1.776357e-14 -1.776357e-14 -2.131628e-14 -2.842171e-14\ras.double(as.character(pi))*(1:10) + as.double(as.character(exp(1))) - x\r## [1] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\r## [6] 3.552714e-15 3.552714e-15 0.000000e+00 0.000000e+00 0.000000e+00\rAnyway this was just a small example. There are many many directions one can choose to take with metaprogramming. Even creating new preprocessing directives such as unrolling loops, defining constexprs, etc.\n\r","date":1592697600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592697600,"objectID":"ca01d41b730a31e858a5873c8ea5b005","permalink":"/post/002_compile_time_data_r_to_cpp/main/","publishdate":"2020-06-21T00:00:00Z","relpermalink":"/post/002_compile_time_data_r_to_cpp/main/","section":"post","summary":"Introduction\rIn this post we give a simple illustrative example of how data generated by R code can be used by compiled languages such as C++ at compile time, instead of run-time, inside Rmarkdown.","tags":["metaprogramming","rmarkdown","c++","rcpp","r"],"title":"Passing expressions and data from R to C++ at compile-time in Rmarkdown","type":"post"},{"authors":null,"categories":["C++","R"],"content":"\rIntroduction\rPrincipal component analysis is one of the most commonly used techniques in statistical modeling and machine learning. In typical applications it serves as a (linear) dimensionality reduction, allowing one to project high dimensional data onto a lower dimensional subspace. This can help make a problem that was previously computationally intractable easier, or can help transform feature variables into something more useful. However, most presentations fail to give a sense of “why” and students are left without an understanding of exactly what PCA is and what assumptions it makes. This can lead to model risk issues and prevent users from being able to modify the technique when different assumptions hold. The purpose of this post is to rectify this with a derivation for those that want to know why, which should be everyone. For fun we implement what we learn at the end in a few lines of C++.\nA note on difficulty\rTo understand what follows you need to understand linear algebra and undergraduate probability. The proof that follows is as clear, honest, and self-contained as I think is possible, but most will not find it easy. In my opinion if a truly easy and theoretically honest proof were possible you would have already seen it.\n\r\rDeriving PCA\rAs scientists our data is often times multidimensional because it involves measurements of many features of the world. Equally often, our data may have some “randomness” in it that we can not capture (so that if the experiment that was run to obtain the data were rerun the results may not be exactly the same).\nLet \\(\\vec{X} = [X^1, X^2, ..., X^d]\\) be a \\(d\\)-dimensional random vector 1 that represents the measured values of \\(d\\) feature variables.\nWe want to capture the “shape” of the randomness of \\(\\vec{X}\\). For example, in what directions does \\(\\vec{X}\\) vary the most? In what directions does it vary the least? This is important because if, for example, \\(\\vec{X}\\) had a lot of randomness in its first coordinate \\(X^1\\), but had very little randomness in the other coordinates, then independent measurements of \\(\\vec{X}\\) would differ a lot in the first coordinate, but not much in the others. The other coordinates would all give roughly the same values and hence roughly the same information. The other coordinates would in a sense be redundant: replacing \\(\\vec{X}\\) by \\(X^1\\) would not lose a lot of information but would have the benefit of having to deal with only 1 feature as opposed to \\(d\\) features (i.e. a dimensionality reduction).\nTo proceed we need to define some measure of variation or randomness. A good one is variance. Our goal is to decompose \\(\\vec{X}\\) into vectors along which \\(\\vec{X}\\) has the most variance. Directions are represented by unit vectors (i.e. vectors of length 1). If \\(\\vec{\\omega}\\) is a non-random unit vector, then the component of \\(\\vec{X}\\) along \\(\\vec{\\omega}\\) is given by\n\\[\r\\langle\\ \\vec{\\omega}\\ ,\\ \\vec{X}\\ \\rangle\\ \\vec{\\omega}\r\\]\rwhere \\(\\langle\\ \\vec{\\omega}\\ ,\\ \\vec{X}\\ \\rangle\\) denotes the inner product in \\(\\mathbb{R}^d\\) (aka, dot product). Since \\(\\vec{\\omega}\\) is not random, the randomness of \\(\\langle\\ \\vec{\\omega}\\ ,\\ \\vec{X}\\ \\rangle\\ \\vec{\\omega}\\) is controlled entirely by the coefficient \\(\\langle\\ \\vec{\\omega}\\ ,\\ \\vec{X}\\ \\rangle\\). To find the direction of maximal variance is to simply find \\(\\vec{\\omega}\\) that maximizes the variance of this inner product. In other words we want\n\\[\r\\vec{\\omega}_1 := \\text{argmax} \\ \\ \\text{Var}( \\langle\\ \\vec{\\omega}\\ ,\\ \\vec{X}\\ \\rangle ) \\]\rwhere the argmax is taken over all \\(\\vec{\\omega}\\) with \\(||\\vec{\\omega}|| = 1\\)2. We begin:\n\\[\\begin{equation}\r\\begin{aligned}\r\\text{Var}( \\langle\\ \\vec{\\omega}\\ ,\\ \\vec{X}\\ \\rangle ) \u0026amp;= \\text{E}\\bigg[\\bigg(\\langle\\ \\vec{\\omega}\\ ,\\ \\vec{X}\\ \\rangle - \\text{E}[\\langle\\ \\vec{\\omega}\\ ,\\ \\vec{X}\\ \\rangle]\\bigg)^2\\bigg] \\\\\r\u0026amp;= \\text{E}[\\langle\\ \\vec{\\omega}\\ , \\ \\vec{X} - \\text{E}[\\vec{X}] \\ \\rangle^2] \\\\\r\u0026amp;= \\text{E}\\bigg[\\ \\bigg(\\sum_i\\omega_i(X^i - \\text{E}[X^i])\\bigg)^2\\bigg] \\\\\r\u0026amp;= \\text{E}\\bigg[ \\sum_{i,j}\\omega_i\\omega_j(X^i - \\text{E}[X^i])(X^j - \\text{E}[X^j]) \\bigg] \\\\\r\u0026amp;= \\sum_{i,j}\\omega_i\\omega_j \\ \\text{E}\\bigg[ \\ (X^i - \\text{E}[X^i])(X^j - \\text{E}[X^j]) \\ \\bigg] \\\\\r\u0026amp;= \\sum_{i,j}\\omega_i\\omega_j \\ \\text{Cov}(X^i, X^j) \\\\\r\u0026amp;= \\langle \\ \\vec{\\omega} \\ , \\ \\text{Cov}(\\vec{X})\\vec{\\omega} \\ \\rangle\r\\end{aligned}\r\\end{equation}\\]\nwhere \\(\\text{Cov}(\\vec{X})\\) is the covariance matrix of \\(\\vec{X}\\). So\n\\[\r\\vec{\\omega}_1 := \\text{argmax} \\ \\ \\langle \\ \\vec{\\omega} \\ , \\ \\text{Cov}(\\vec{X})\\vec{\\omega} \\ \\rangle \\]\ragain the argmax is taken over all \\(\\vec{\\omega}\\) with \\(||\\vec{\\omega}|| = 1\\). This problem is called a “variational problem”, but why so is not important at the moment.\nThis \\(\\vec{\\omega}_1\\) must be the first eigenvector of the matrix \\(\\text{Cov}(\\vec{X})\\). Why? This is the hard part. If you can understand what follows you’re golden. There are multiple ways to see why this is the case:\nOne is by Lagrange multipliers. If we write \\(f(\\vec{\\omega}) := \\langle \\ \\vec{\\omega} \\ , \\ \\text{Cov}(\\vec{X})\\vec{\\omega} \\ \\rangle\\) then\n\\[\\begin{equation}\r\\begin{aligned}\rf(\\vec{\\omega} + \\vec{h}) - f(\\vec{\\omega}) \u0026amp;= \\langle \\ \\vec{\\omega} + \\vec{h} \\ , \\ \\text{Cov}(\\vec{X})(\\vec{\\omega}+\\vec{h}) \\ \\rangle - \\langle \\ \\vec{\\omega} \\ , \\ \\text{Cov}(\\vec{X})\\vec{\\omega} \\ \\rangle \\\\\r\u0026amp;= \\langle \\ \\vec{h} \\ , \\ \\text{Cov}(\\vec{X})\\vec{\\omega} \\ \\rangle + \\langle \\ \\vec{\\omega} \\ , \\ \\text{Cov}(\\vec{X})\\vec{h}\\rangle \\ + \\langle \\ \\vec{h} \\ , \\ \\text{Cov}(\\vec{X})\\vec{h} \\rangle \\\\\r\u0026amp;= 2\\langle \\ \\vec{h} \\ , \\ \\text{Cov}(\\vec{X})\\vec{\\omega} \\ \\rangle + \\langle \\ \\vec{h} \\ , \\ \\text{Cov}(\\vec{X})\\vec{h} \\rangle\r\\end{aligned}\r\\end{equation}\\]\nwhere we first expanded the first term using the bilinearity of the inner product, canceled like terms, and lastly used the symmetry of the covariance matrix to combine two terms. In the above expression the first order term in \\(\\vec{h}\\) is given by \\(\\langle \\ \\vec{h} \\ , \\ 2\\text{Cov}(\\vec{X})\\vec{\\omega} \\ \\rangle\\). The other term is quadratic in \\(\\vec{h}\\). By definition the differential of \\(f\\) at \\(\\vec{\\omega}\\) is this linear term:\n\\[\rdf_{\\vec{\\omega}} \\ (\\vec{h}) = \\langle \\ \\vec{h} \\ , \\ 2\\text{Cov}(\\vec{X})\\vec{\\omega} \\ \\rangle\r\\]\nBy definition3 the gradient of \\(f\\) at \\(\\vec{\\omega}\\) is just the vector in the above expression which the inner product with \\(\\vec{h}\\) is being taken:\n\\[\r\\nabla_{\\vec{\\omega}} f = 2 \\ \\text{Cov}(\\vec{X}) \\ \\vec{\\omega}\r\\]\rBecause our variational problem is to maximize \\(f(\\vec{\\omega})\\) on the unit sphere where \\(||\\vec{\\omega}|| = 1\\), then the gradient of \\(f\\) at the maximizing point \\(\\vec{\\omega}_1\\) must be orthogonal (i.e. perpendicular, i.e. normal) to the surface of the unit sphere at that point4. The direction (i.e. unit vector) perpendicular to the unit sphere at \\(\\vec{\\omega}_1\\) is \\(\\vec{\\omega}_1\\) itself with its starting point translated to the surface!\nThus the gradient of \\(f\\) at \\(\\vec{\\omega}_1\\) must be collinear with (and hence a multiple of) \\(\\vec{\\omega}_1\\):\n\\[\r\\nabla_{\\vec{\\omega}_1}f = \\lambda\u0026#39; \\ \\vec{\\omega}_1\r\\]\rfor some number \\(\\lambda\u0026#39;\\). Thus\n\\[\r\\text{Cov}(\\vec{X}) \\ \\vec{\\omega}_1 = \\frac{\\lambda\u0026#39;}{2} \\ \\vec{\\omega}_1 =: \\lambda \\ \\vec{\\omega}_1\r\\]\rHence \\(\\vec{\\omega}_1\\) is an eigenvector of \\(\\text{Cov}(\\vec{X})\\). We note that the eigenvalue \\(\\lambda\\) is just the variance we wanted to maximize:\n\\[\r\\langle \\ \\vec{\\omega}_1 \\ , \\ \\text{Cov}(\\vec{X}) \\ \\vec{\\omega}_1 \\ \\rangle = \\langle \\ \\vec{\\omega}_1 \\ , \\lambda \\vec{\\omega}_1 \\ \\rangle = \\lambda\\langle \\ \\vec{\\omega}_1 \\ , \\vec{\\omega}_1 \\ \\rangle = \\lambda ||\\vec{\\omega}||^2 = \\lambda\r\\]\rThus we see that eigenvectors capture directions of maximal variance and eigenvalues capture the value of the variance in that maximal direction! We can also see why the variance is a nice measure of variation/randomness. Because it’s quadratic in its arguments, derivatives of it become linear, leading to linear eigenvalue problems, which are very well understood by mathematicians.\nWe proceed as follows. Let \\(\\vec{X}_{new} = \\vec{X} - \\langle\\vec{\\omega}_1,\\vec{X}\\rangle\\vec{\\omega}_1\\). This \\(\\vec{X}_{new}\\) is just the component of \\(\\vec{X}\\) orthogonal to \\(\\vec{\\omega}_1\\). Intuitively it’s the part of \\(\\vec{X}\\) that \\(\\vec{\\omega}_1\\) can not explain.\nJust as before we want to capture the direction of maximal variance of \\(\\vec{X}_{new}\\). I.e. we want a vector \\(\\vec{\\omega}_2\\) with \\(||\\vec{\\omega}_2||=1\\) such that \\(\\text{Var}(\\langle \\vec{\\omega}_2, \\vec{X}_{new}\\rangle)\\) is maximal.\nSince \\(\\vec{X}_{new} \\perp \\vec{\\omega}_1\\)5 then \\(\\langle \\vec{\\omega}, \\vec{X}_{new}\\rangle = \\langle \\vec{\\omega} - \\alpha\\vec{\\omega}_1, \\vec{X}_{new}\\rangle\\) for any \\(\\alpha \\in \\mathbb{R}\\). Therefore by replacing \\(\\vec{\\omega}\\) with \\(\\vec{\\omega} - \\langle\\vec{\\omega}_1,\\vec{\\omega}\\rangle\\vec{\\omega}_1\\) we may restrict our maximization problem to maximizing \\(\\text{Var}(\\langle \\vec{\\omega}, \\vec{X}_{new}\\rangle)\\) over all \\(\\vec{\\omega}\\) with \\(||\\vec{\\omega}|| = 1\\) and \\(\\vec{\\omega} \\perp \\vec{\\omega}_1\\).\nWe transform this expression as follows:\n\\[\\begin{equation}\r\\begin{aligned}\r\\text{Var}(\\langle \\vec{\\omega}, \\vec{X}_{new}\\rangle) \u0026amp;= \\text{Var}(\\langle \\vec{\\omega}, \\vec{X} - \\langle\\vec{\\omega}_1,\\vec{X}\\rangle\\vec{\\omega}_1\\rangle) \\\\\r\u0026amp;= \\text{Var}(\\langle \\vec{\\omega}, \\vec{X}\\rangle) \\qquad \\text{Since }\\vec{\\omega}\\perp\\vec{\\omega}_1 \\\\\r\u0026amp;= \\langle \\vec{\\omega}, \\text{Cov}(\\vec{X})\\vec{\\omega}\\rangle \\qquad \\text{By the earlier computation}\r\\end{aligned}\r\\end{equation}\\]\nSo the vector \\(\\vec{\\omega}_2\\) is given by the new variational problem\n\\[\r\\vec{\\omega}_2 = \\text{argmax} \\ \\langle \\vec{\\omega}, \\text{Cov}(\\vec{X})\\vec{\\omega}\\rangle\r\\]\rwhere the argmax is taken over all \\(\\vec{\\omega}\\) with \\(||\\vec{\\omega}|| = 1\\) and \\(\\vec{\\omega} \\perp \\vec{\\omega}_1\\). Now \\(\\langle \\vec{\\omega}_2, \\vec{X}_{new}\\rangle = \\langle \\vec{\\omega}_2, \\vec{X}\\rangle\\) is of maximal variance in a direction perpendicular to \\(\\vec{\\omega}_1\\).\nNotice that this is the same maximization problem as before, but now restricted to a lower dimensional subspace (the subspace that is prependicular to \\(\\vec{\\omega}_1\\)). The same Lagrange multiplier calculation as before can be applied again in this subspace. This shows that \\(\\vec{\\omega}_2\\) is an eigenvector of \\(\\text{Cov}(\\vec{X})\\) with eigenvalue \\(\\langle \\vec{\\omega}_2, \\text{Cov}(\\vec{X})\\vec{\\omega}_2\\rangle\\). This eigenvalue must be less than or equal to the eigenvalue of \\(\\vec{\\omega}_1\\) because the maximum of the same expression is being taken over a smaller set for \\(\\vec{\\omega}_2\\).\nWe can continue this process until all eigenvectors are exhausted. By decomposing \\(\\vec{X}\\) into linear combinations of the eigenvectors \\(\\vec{\\omega}_i\\) we may choose to capture as much or as little of the variance of \\(\\vec{X}\\) as we please. For example, by projecting onto the first k eigenvectors we may capture the k-dimensional variance of \\(\\vec{X}\\):\n\\[\r\\vec{X}_k := \\sum_{i = 1}^k\\langle\\vec{\\omega}_i,\\vec{X}\\rangle\\vec{\\omega}_i\r\\]\n\rSample estimators\rIn practice we do not know the matrix \\(\\text{Cov}(\\vec{X})\\), but instead have a data matrix \\(\\{ \\vec{X}_j \\}_{j=1}^N\\) of row vectors representing realizations of the random vector \\(\\vec{X}\\).\nStatistics is often concerned with constructing sample estimators of quantities. If our data rows are sampled IID from the distribution of \\(\\vec{X}\\) then in lieu of \\(\\text{Cov}(X^i,X^j)\\) we construct the sample covariances:\n\\[\rS^2_{i,j} := \\frac{1}{N-1}\\sum_{n=1}^N\\bigg(X^i_n - \\bar{X}^i\\bigg)\\bigg(X^j_n - \\bar{X}^j\\bigg)\r\\]\rwhere \\(\\bar{X}^i\\) is the mean of the \\(i^{\\text{th}}\\) feature column. This estimator is a statistic constructed for its favorable distributional properties under IID assumptions as \\(N\\) becomes large. In particular, it converges to \\(\\text{Cov}(X^i,X^j)\\) in some sense.\n\rImplementing in Eigen\rThe derivation above gives us one formula to carry out PCA: simply compute the sample covariance matrix of the data and extract its eigenvectors and eigenvalues. This may or may not be the most numerically efficient/stable algorithm to use (I haven’t checked), but this is easy enough to implement in most numerical computing languages. Here we implement it in C++ using the Eigen library. To make it more interactive we use the RcppEigen package in R to allow using the function in R sessions:\n#include \u0026lt;RcppEigen.h\u0026gt;\r// [[Rcpp::depends(RcppEigen)]]\rusing namespace Eigen;\r// [[Rcpp::export]]\rRcpp::List EigenDecomp(const Map\u0026lt;MatrixXd\u0026gt; M) {\r//Constructing sample covariance matrix MatrixXd centered = M.rowwise() - M.colwise().mean();\rMatrixXd cov = centered.adjoint() * centered/(M.rows()-1);\r//Using Eigen\u0026#39;s eigensolver (with default settings)\rSelfAdjointEigenSolver\u0026lt;MatrixXd\u0026gt; eig(cov);\rVectorXd values = eig.eigenvalues();\rMatrixXd vectors = eig.eigenvectors();\r//Returning results as a R-list\rreturn Rcpp::List::create(Rcpp::Named(\u0026quot;Cov\u0026quot;) = cov,\rRcpp::Named(\u0026quot;values\u0026quot;) = values,\rRcpp::Named(\u0026quot;vectors\u0026quot;) = vectors);\r}\rNote on compilation: I’m using a laptop with an i7-8750h CPU running Windows 10. The compiler is the version of mingw-w64 that comes with Rtools40 (i.e. the Windows port of GCC 8.3.0). By creating a Makevars.win file in an ./Documents/.R folder file I altered R’s default flags for g++ to use:\nCXXFLAGS = -march=native -O3 -Wno-ignored-attributes $(DEBUGFLAG)\rEigen is a template expression library that relies heavily on the compiler using the best options for the machine at hand. Here we’ve used -march=native which enables all instruction subsets supported by my local machine. For more info running g++ -march=native -Q --help=target in the command line will show you what compiler flags this turns on. For example mine enables flags targeting AVX2, as well as a variety of others. The -Wno-ignored-attributes suppresses the large number of ignored attributes warnings that an expression template library like Eigen can produce. Let’s compare with R’s built in PCA function prcomp\nset.seed(42)\rX = matrix(rnorm(10000*4), 10000, 4)\rR = prcomp(X)\rCpp = EigenDecomp(X)\rprint(R$sdev^2)\r## [1] 1.036884 1.021022 1.013685 1.001778\rprint(Cpp$values)\r## [1] 1.001778 1.013685 1.021022 1.036884\rThe eigenvalues are exactly the same, just in opposite order. Next time we might link an optimized BLAS library such as Intel’s MKL, but I suspect the plain Eigen version is quite competitive.\n\r\rThe exact definition of “random variable” or “random vector” is unimportant. For mathematicians this means that there is a probability space \\((\\Omega, \\mathcal{M}, \\mathbf{P})\\) and that \\(\\vec{X}:\\Omega \\mapsto \\mathbb{R}^d\\) is a Borel-measurable map.↩︎\n\rNote on existence. A vector that attains the maximum must exist because the expression being maximized is continuous (in fact quadratic) in \\(\\vec{\\omega}\\) and the unit sphere in \\(\\mathbb{R}^d\\) is compact.↩︎\n\rAnd this is indeed the true definition of the gradient of a function.↩︎\n\rThis is the method of Lagrange multipliers. It can be proven easily as follows. Let \\(\\vec{v}\\) be any vector tangent to the sphere at the maximizing point \\(\\vec{\\omega}_1\\), and let \\(\\gamma(t)\\) be a smooth curve on the sphere going through \\(\\vec{\\omega}_1\\) with \\(\\gamma\u0026#39;(t) = \\vec{v}\\). Then the function \\(f(\\gamma(t))\\) achieves a maximum at the value of \\(t\\) at which \\(\\gamma(t) = \\vec{\\omega}_1\\) so it’s derivative must be 0 there. Thus \\(0 = d/dt(f(\\gamma(t))) = df_{\\vec{\\omega}_1} \\ (\\gamma\u0026#39;(t)) = \\langle \\gamma\u0026#39;(t),\\nabla_{\\vec{\\omega}_1}f\\rangle = \\langle\\vec{v},\\nabla_{\\vec{\\omega}_1}f\\rangle\\). Since \\(\\vec{v}\\) was an arbitrary tangent vector this shows that \\(\\nabla_{\\vec{\\omega}_1}f\\) is orthogonal to every tangent vector and hence is a normal vector.↩︎\n\rThe symbol \\(\\perp\\) means “prependicular to”.↩︎\n\r\r\r","date":1592611200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592611200,"objectID":"6780a995639cbbd39e5adbc2b9112e85","permalink":"/post/001_deriving_pca/main/","publishdate":"2020-06-20T00:00:00Z","relpermalink":"/post/001_deriving_pca/main/","section":"post","summary":"Introduction\rPrincipal component analysis is one of the most commonly used techniques in statistical modeling and machine learning. In typical applications it serves as a (linear) dimensionality reduction, allowing one to project high dimensional data onto a lower dimensional subspace.","tags":["dimensionality reduction","pca","eigen","c++","derivation","rcpp","r"],"title":"Deriving Principal Component Analysis and implementing in C++ using Eigen","type":"post"},{"authors":["Edger Sterjo"],"categories":null,"content":" Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"An example preprint / working paper","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":null,"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":null,"title":"Internal Project","type":"project"},{"authors":["Edger Sterjo","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"An example journal article","type":"publication"},{"authors":["Edger Sterjo","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"An example conference paper","type":"publication"}]