---
title: 'Parallel Monte Carlo: Simulating Compound Poisson Processes using C++ and
  TBB'
author: "Edger Sterjo"
date: '2020-11-20'
categories:
- C++
- R
- TBB
tags:
- parallel
- monte carlo
- poisson
- c++
- operational risk
- rcpp
- r
---



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>In this post we implement a function to simulate random samples of a <a href="https://en.wikipedia.org/wiki/Compound_Poisson_process">Compound Poisson variable</a>. A random variable <span class="math inline">\(L\)</span> is a compound Poisson (CP) random variable if there exists a Poisson random variable <span class="math inline">\(N\)</span>, and a random variable <span class="math inline">\(S\)</span> such that</p>
<p><span class="math display">\[
L = \sum_{i = 1}^N S_i
\]</span></p>
<p>where <span class="math inline">\(S_i\)</span> for <span class="math inline">\(i \in \mathbb{N}\)</span> is an IID sequence of random variables with the same distribution as <span class="math inline">\(S\)</span> and that are independent of <span class="math inline">\(N\)</span>. This kind of expression is typical in operational risk modeling, insurance modeling, and <a href="https://en.wikipedia.org/wiki/Ruin_theory">ruin theory</a>. Typically, the variable <span class="math inline">\(N\)</span> is a counter for the occurrence of loss events to an insurance portfolio over a given time period, and <span class="math inline">\(S_i\)</span> is the severity of the <span class="math inline">\(i\)</span>-th loss event. A CP variable/process is the most common approach banks take to model operational risk as part of their <a href="https://en.wikipedia.org/wiki/Advanced_measurement_approach">Advanced Measurement Approach</a>. The advantage of this model in operational risk is that losses (and hence data) tend to be sparse in this domain. In addition, losses tend to be heavy tailed. By splitting event frequency (<span class="math inline">\(N\)</span>) from event severity (<span class="math inline">\(S\)</span>) the model developer can use more data to fit loss severity distributions and loss frequency distributions independently (after accepting the assumptions of the CP process). This assumption of IID losses allows the modeler to focus on fitting the tail of the loss distribution, without having to worry about the frequency of occurrences.</p>
<p>We’ll implement a function that simulates random samples of <span class="math inline">\(L\)</span> in R, serially in C++, and in parallel in C++ using the <a href="https://github.com/oneapi-src/oneTBB">Threading Building Blocks (TBB)</a> library.</p>
</div>
<div id="r-implementation" class="section level2">
<h2>R Implementation</h2>
<p>R is extremely expressive when it comes to mathematical, statistical, and graphing operations and the base implementation is quite simple:</p>
<pre class="r"><code>## Function to simulate random samples from a CP variable with 
## log-normal severities
rCP = function(lambda, mu, sigma, N)
{
    sapply(1:N, FUN = function(dummy){
        sum(rlnorm(n = rpois(1, lambda), meanlog = mu, sdlog = sigma))
    })
}</code></pre>
</div>
<div id="serial-c-implementation" class="section level2">
<h2>Serial C++ Implementation</h2>
<p>We now implement the sampler in C++ using the <a href="http://www.rcpp.org/">Rcpp package</a>. We will also make use of the <a href="https://cran.r-project.org/web/packages/dqrng/index.html">dqrng</a> package so that we can conveniently include the <a href="https://www.pcg-random.org/">PCG</a> random number generator by Melissa O’Neil.</p>
<pre class="cpp"><code>#include &lt;Rcpp.h&gt;

// [[Rcpp::depends(dqrng)]]

#include &lt;pcg_random.hpp&gt;
#include &lt;random&gt;
#include &lt;algorithm&gt;

// [[Rcpp::export]]
Rcpp::NumericVector cppCP(const double lambda,
                          const double mu,
                          const double sigma,
                          const int N)
{
    // Seed with a real random value, if available
    pcg_extras::seed_seq_from&lt;std::random_device&gt; seed_source;

    // Make a random number engine
    pcg64 rng(seed_source);
    
    // Distribution for frequency
    std::poisson_distribution&lt;int&gt; Freq(lambda);
    
    // Distribution for severity
    std::lognormal_distribution&lt;double&gt; Sev(mu, sigma);
    
    // Allocate vector
    Rcpp::NumericVector out(N);

    // Simulate samples
    std::generate(out.begin(), out.end(), [&amp;](){
        
        // Simulating loss event count
        int n = Freq(rng);
        
        // Accumulating loss severities
        double s = 0;
        for(int i = 0; i &lt; n; ++i) s += Sev(rng);
        
        return s;
    });
    
    return out;
}</code></pre>
<pre class="r"><code>x_r = rCP(lambda = 1.7, mu = 5.5, sigma = 2.5, N = 10^6)
x_cpp = cppCP(lambda = 1.7, mu = 5.5, sigma = 2.5, N = 10^6)

ks.test(x = x_r, y = x_cpp, alternative = &quot;two.sided&quot;)</code></pre>
<pre><code>## Warning in ks.test(x = x_r, y = x_cpp, alternative = &quot;two.sided&quot;): p-value will
## be approximate in the presence of ties</code></pre>
<pre><code>## 
##  Two-sample Kolmogorov-Smirnov test
## 
## data:  x_r and x_cpp
## D = 0.000963, p-value = 0.7427
## alternative hypothesis: two-sided</code></pre>
<pre class="r"><code>microbenchmark::microbenchmark(
    &quot;R&quot; = rCP(lambda = 1.7, mu = 5.5, sigma = 2.5, N = 10^6),
    &quot;C++&quot; = cppCP(lambda = 1.7, mu = 5.5, sigma = 2.5, N = 10^6),
    times = 10L
    )</code></pre>
<pre><code>## Unit: milliseconds
##  expr       min         lq       mean     median         uq       max neval
##     R 4268.0577 4331.33293 4358.51965 4357.96885 4401.17094 4416.6745    10
##   C++   70.8535   70.96943   77.22742   71.20739   71.51722  128.0817    10</code></pre>
<p>We see that a Kolmogorov-Smirnov test for equality of distributions shows that the two samples aren’t statistically distinct. Also the C++ version is ~30 times faster than the R version. Note that we added the compilation flags <code>-O3 -march=native</code> to R’s Makeoconf file (although one could simply register a plugin with Rcpp or use a makevars file in a package).</p>
</div>
<div id="parallel-c-implementation" class="section level2">
<h2>Parallel C++ Implementation</h2>
<p>There are many libraries we can use to parallelize the C++ code above. These include <a href="https://www.openmp.org/">OpenMP</a> and <a href="https://www.openacc.org/">OpenACC</a> (both of which allow for standards based parallelization through directive based APIs, with newer standards allowing for GPU offloading), <a href="https://www.open-mpi.org/">MPI</a> and <a href="https://www.boost.org/doc/libs/1_74_0/doc/html/mpi.html">Boost.MPI</a> for distributed messaging passing, <a href="https://github.com/kokkos/kokkos">Kokkos</a>, <a href="https://github.com/taskflow/taskflow">Taskflow</a>, <a href="https://github.com/boostorg/compute">Boost.Compute</a>, <a href="https://github.com/STEllAR-GROUP/hpx/">HPX</a>, etc.</p>
<p>However, <a href="https://rcppcore.github.io/RcppParallel/tbb.html">Threading Building Blocks (TBB)</a> is very powerful, expressive, mature, and is very conveniently included in the <a href="https://rcppcore.github.io/RcppParallel/">RcppParallel</a> package. I find TBB’s API to be very well designed. So TBB it is!</p>
<pre class="cpp"><code>#include &lt;Rcpp.h&gt;
#include &lt;RcppParallel.h&gt;

// [[Rcpp::depends(dqrng, RcppParallel)]]

#include &lt;pcg_random.hpp&gt;
#include &lt;random&gt;
#include &lt;algorithm&gt;



// [[Rcpp::export]]
Rcpp::NumericVector tbbCP(const double lambda,
                          const double mu,
                          const double sigma,
                          const int N,
                          const uint64_t seed)
{
    using brange = tbb::blocked_range&lt;size_t&gt;;
    
    // Allocate vector
    Rcpp::NumericVector out(N);
    
    // Getting pointer to data
    auto begin = out.begin();
    
    tbb::parallel_for(brange(0, N), [=](brange&amp; range){
        
        // Distribution for frequency
        std::poisson_distribution&lt;int&gt; Freq(lambda);
    
        // Distribution for severity
        std::lognormal_distribution&lt;double&gt; Sev(mu, sigma);
        
        // RNG local to thread, with unique stream
        pcg64 rng(seed, range.end());
        
        // Serial version of sampler
        auto seq_CP = [&amp;](){
            
            // Simulating loss event count
            int n = Freq(rng);
            
            // Accumulating loss severities
            double s = 0;
            for(int i = 0; i &lt; n; ++i) s += Sev(rng);
            
            return s;
        };
        
        // Loop to simulate samples
        std::generate(begin + range.begin(), begin + range.end(), seq_CP);
    });
    
    return out;
}</code></pre>
<p>C++11 and TBB allow for pretty parallel code. Let’s see if this function is as useful as it is pretty.</p>
<pre class="r"><code>x_tbb = tbbCP(lambda = 1.7, mu = 5.5, sigma = 2.5, N = 10^6, seed = 42)

ks.test(x = x_cpp, y = x_tbb, alternative = &quot;two.sided&quot;)</code></pre>
<pre><code>## Warning in ks.test(x = x_cpp, y = x_tbb, alternative = &quot;two.sided&quot;): p-value
## will be approximate in the presence of ties</code></pre>
<pre><code>## 
##  Two-sample Kolmogorov-Smirnov test
## 
## data:  x_cpp and x_tbb
## D = 0.000891, p-value = 0.8222
## alternative hypothesis: two-sided</code></pre>
<pre class="r"><code>ks.test(x = x_r, y = x_tbb, alternative = &quot;two.sided&quot;)</code></pre>
<pre><code>## Warning in ks.test(x = x_r, y = x_tbb, alternative = &quot;two.sided&quot;): p-value will
## be approximate in the presence of ties</code></pre>
<pre><code>## 
##  Two-sample Kolmogorov-Smirnov test
## 
## data:  x_r and x_tbb
## D = 0.001349, p-value = 0.3227
## alternative hypothesis: two-sided</code></pre>
<pre class="r"><code>p = c(0.5, 0.75, 0.9, 0.95, 0.99, 0.999, 0.9999)
data.frame(R = quantile(x_r, probs = p), 
           Cpp = quantile(x_cpp, probs = p), 
           TBB = quantile(x_tbb, probs = p))</code></pre>
<pre><code>##                   R          Cpp          TBB
## 50%        525.6721     527.8515     525.2247
## 75%       3188.0650    3205.9785    3215.0528
## 90%      13007.0777   12989.6880   13043.5109
## 95%      29284.5478   29428.5408   29399.1686
## 99%     137016.4653  136261.8314  139049.8941
## 99.9%   821332.7436  794316.1106  845872.3186
## 99.99% 3864860.8800 3319502.5073 4282836.7037</code></pre>
<p>The Kolmogorov-Smirnov test again can’t tell the samples apart between R, serial C++, and TBB implementations. Let’s take a look at the spacing between consecutive percentiles for non-zero values. If the RNGs between different threads overlapped in the parallel implementation, this would be a first way to find out as differences between the sorted values would show a spike at 0</p>
<pre class="r"><code>library(magrittr)

y_r = x_r[x_r &gt; 0] %&gt;% sort(decreasing = FALSE) %&gt;% diff()
y_tbb = x_tbb[x_tbb &gt; 0 ] %&gt;% sort(decreasing = FALSE) %&gt;% diff()

ks.test(y_r, y_tbb, alternative = &quot;two.sided&quot;)</code></pre>
<pre><code>## Warning in ks.test(y_r, y_tbb, alternative = &quot;two.sided&quot;): p-value will be
## approximate in the presence of ties</code></pre>
<pre><code>## 
##  Two-sample Kolmogorov-Smirnov test
## 
## data:  y_r and y_tbb
## D = 0.0013749, p-value = 0.4224
## alternative hypothesis: two-sided</code></pre>
<pre class="r"><code>data.frame(R = quantile(y_r, probs = p), 
           TBB = quantile(y_tbb, probs = p))</code></pre>
<pre><code>##                   R          TBB
## 50%    4.706155e-03 4.696845e-03
## 75%    2.789482e-02 2.799611e-02
## 90%    1.927010e-01 1.922044e-01
## 95%    7.343613e-01 7.353753e-01
## 99%    1.342726e+01 1.425215e+01
## 99.9%  6.736032e+02 6.651423e+02
## 99.99% 2.541149e+04 2.965516e+04</code></pre>
</div>
<div id="final-performance-comparison" class="section level2">
<h2>Final Performance Comparison</h2>
<pre class="r"><code>microbenchmark::microbenchmark(
    &quot;R&quot; = rCP(lambda = 1.7, mu = 5.5, sigma = 2.5, N = 10^6),
    &quot;C++&quot; = cppCP(lambda = 1.7, mu = 5.5, sigma = 2.5, N = 10^6),
    &quot;TBB&quot; = tbbCP(lambda = 1.7, mu = 5.5, sigma = 2.5, N = 10^6, seed = 42),
    times = 10L
    )</code></pre>
<pre><code>## Unit: milliseconds
##  expr        min          lq        mean      median          uq        max
##     R 4257.52277 4386.657195 4419.765148 4439.142598 4464.874526 4497.83768
##   C++   70.69678   70.932022   71.548681   71.373135   72.201374   72.53289
##   TBB    9.31567    9.440707    9.578117    9.507002    9.641842   10.27413
##  neval
##     10
##     10
##     10</code></pre>
<p>TBB ran ~8 times faster than the serial version. The algorithm’s runtime scales linearly with <span class="math inline">\(\lambda\)</span>, so let’s compare the two C++ versions with a higher lambda:</p>
<pre class="r"><code>microbenchmark::microbenchmark(
    &quot;C++&quot; = cppCP(lambda = 17, mu = 5.5, sigma = 2.5, N = 10^6),
    &quot;TBB&quot; = tbbCP(lambda = 17, mu = 5.5, sigma = 2.5, N = 10^6, seed = 42),
    times = 50L
    )</code></pre>
<pre><code>## Unit: milliseconds
##  expr       min        lq      mean    median       uq       max neval
##   C++ 585.05328 587.97749 595.12652 595.08056 601.1128 610.35413    50
##   TBB  68.66768  69.74909  71.06729  70.30209  71.6615  82.82758    50</code></pre>
<p>TBB ran ~9.5 times faster than the serial version.</p>
</div>
